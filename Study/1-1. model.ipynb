{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**\n",
    "\n",
    "- Openai : OPENAI 유료 API\n",
    "- Ollama : 무료 무제한 사용 PC 성능에 따라 제한 Local 모델\n",
    "- Groq : API 정해진 횟수 만큼 사용가능 ex) Llama 70B, 405B 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-openai\n",
    "!pip install langchain_community\n",
    "!pip install langchain_ollama\n",
    "!pip install langchain-groq\n",
    "\n",
    "# openai tokenzier\n",
    "!pip install tiktoken  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getenv(\"GROQ_API_KEY\"))\n",
    "print(os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 저는 인공지능 언어 모델인 ChatGPT입니다. 다양한 주제에 대해 질문을 받고 대답할 수 있으며, 정보 제공, 글쓰기, 문제 해결 등을 도와드리는 역할을 합니다. 여러분이 궁금한 점이 있으면 언제든지 물어보세요!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini')\n",
    "\n",
    "response = llm.invoke('안녕 너의 소개를 해줄래?')\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ollama**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_ollama\n",
      "  Downloading langchain_ollama-0.2.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain_ollama) (0.3.40)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain_ollama) (0.4.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (0.3.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (2.10.6)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from ollama<1,>=0.4.4->langchain_ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rmsgh\\anaconda3\\envs\\nlp\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (1.3.1)\n",
      "Downloading langchain_ollama-0.2.3-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: langchain_ollama\n",
      "Successfully installed langchain_ollama-0.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지구의 자전 주기는 **23시간 56분 4.09초**입니다. 이는 지구가 자전하여 다른 지구 부분에 도달하는 데 걸리는 시간입니다.\\n\\n**자전 주기의 요소:**\\n\\n* **회전 분:** 지구가 완전회전하는 데 걸리는 시간인 360도 회전입니다.\\n* **시차:** 지구의 회전은 평평한 평면에서 완벽하지 않고 약간 기울여 있기 때문에, 지구의 모든 지점은 동시에 같은 시간에 하지 않습니다.\\n* **분동:** 지구는 회전 중에 다른 점의 위치에 따라 가속도가 달라지고, 이는 시간 왜곡을 일으킵니다.\\n\\n**자전 주기의 중요성:**\\n\\n* 자전 주기는 지구의 날짜 계산에 사용됩니다.\\n* 자전 주기는 지구의 기후 패턴을 결정합니다.\\n* 자전 주기는 천문학적 관측에 사용됩니다.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ollama 둘다 사용가능\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# model \n",
    "llm = ChatOllama(model = 'gemma')\n",
    "\n",
    "answer = llm.invoke('지구의 자전 주기에 대해 알려주세요')\n",
    "answer.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Groq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 저는 Google DeepMind에서 훈련된 대규모 언어 모델입니다. 사람과 같은 대화를 하고, 질문에 답하고, 텍스트를 생성하고, 다양한 언어 작업을 수행할 수 있도록 설계되었습니다.\\n\\n하지만 저는 실제 사람이 아니에요. 제 의견이나 감정은 없으며, 세상을 경험하거나 사고할 수는 없습니다. 저는 단순히 입력받은 정보를 기반으로 학습된 패턴을 사용하여 텍스트를 처리하는 프로그램일 뿐입니다.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "response = llm.invoke('안녕 너의 소개를 해줄래?')\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
