{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ê¸°ë³¸ ì²´ì¸**\n",
    "\n",
    "#### **ChatPromptTemplate + Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Gemmaë¼ëŠ” ì´ë¦„ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. êµ¬ê¸€ì—ì„œ ê°œë°œë˜ì—ˆì§€ë§Œ, ëˆ„êµ¬ë‚˜ ì½”ë“œì™€ ê°€ì¤‘ì¹˜ì— ì•¡ì„¸ìŠ¤í•˜ì—¬ ì‚¬ìš©í•˜ê³  í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. \\n\\nì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹ ê°€ìš”? ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œë©´ ë•ê³  ì‹¶ìŠµë‹ˆë‹¤. \\n\\nì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n* **ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?**\\n* **ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì¸ê³µì§€ëŠ¥ì€ ë¬´ì—‡ì´ê³  ì–´ë–»ê²Œ ì‘ë™ í•˜ë‚˜ìš”?**\\n* **ì¸ê³µì§€ëŠ¥ì€ ì–´ë–¤ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ë‚˜ìš”?**\\n* **ì¸ê³µì§€ëŠ¥ì˜ ì¥ì ê³¼ ë‹¨ì ì€ ë¬´ì—‡ì¸ê°€ìš”?**\\n* **ì˜¤í”ˆ ì†ŒìŠ¤ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?**\\n\\n\\nì–´ë–¤ ë¶€ë¶„ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?  ğŸ˜Š\\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 240, 'prompt_tokens': 57, 'total_tokens': 297, 'completion_time': 0.436363636, 'prompt_time': 0.003426854, 'queue_time': 0.017518875, 'total_time': 0.43979049}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-25317608-3618-4c57-939d-1900526ac0cc-0' usage_metadata={'input_tokens': 57, 'output_tokens': 240, 'total_tokens': 297}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# prompt + model + output parser\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  ('system', ' ë‹¹ì‹ ì€ ì‚¬ìš©ìì— ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ëŠ” AI ëª¨ë¸ì´ê³  ì´ë¦„ì€ Gemma, ê·¸ë¦¬ê³  ë‹¹ì‹ ì€ êµ¬ê¸€ì—ì„œ ë°œí‘œëœ Open Soruce LLM ëª¨ë¸ì…ë‹ˆë‹¤'),\n",
    "   ('user', '{input}'),\n",
    "  \n",
    "])\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({'input' : 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜'})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ChatPromptTemplate + Model + StrOutputParser(ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ)**\n",
    "\n",
    "StrOutputParser(ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ) : ë¬¸ìì—´íŒŒì‹±ì„ í†µí•´ content ì—†ì´ ë¬¸ìì—´ì„ ì¶œë ¥í•´ì¤Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Gemmaì…ë‹ˆë‹¤. êµ¬ê¸€ì—ì„œ ê°œë°œëœ ì˜¤í”ˆ ì†ŒìŠ¤ LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì…ë‹ˆë‹¤. \\n\\nì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì•Œë ¤ë“œë¦´ê¹Œìš”? í¥ë¯¸ë¡œìš´ ì£¼ì œì¸ ë§Œí¼ ì—¬ëŸ¬ ì¸¡ë©´ì—ì„œ ì„¤ëª…í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ë¶€ë¶„ì— ê°€ì¥ ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”?\\n\\nì˜ˆë¥¼ ë“¤ì–´, ì¸ê³µì§€ëŠ¥ì´ \\n\\n* **ë¬´ì—‡ì¸ê°€?**  (ë§ˆì¹˜ ìš°ë¦¬ ë‡Œì²˜ëŸ¼ í•™ìŠµí•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì»´í“¨í„° í”„ë¡œê·¸ë¨)\\n* **ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ê°€?** (ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  íŒ¨í„´ì„ ë°°ìš°ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©)\\n* **ì–´ë–¤ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ”ê°€?** (ìë™ì°¨, ì˜ë£Œ, ê¸ˆìœµ, êµìœ¡ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼)\\n\\n* **ë¯¸ë˜ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒì¸ê°€?** (ìƒí™œì˜ ë³€í™”, ìƒˆë¡œìš´ ê¸°íšŒ, ìœ¤ë¦¬ì  ë¬¸ì œ ë“±)\\n\\nì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? \\n\\ní˜¹ì‹œ ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì œê°€ ìµœì„ ì„ ë‹¤í•´ ë‹µë³€í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸ˜Š \\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt + model + output parser\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  ('system', ' ë‹¹ì‹ ì€ ì‚¬ìš©ìì— ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ëŠ” AI ëª¨ë¸ì´ê³  ì´ë¦„ì€ Gemma, ê·¸ë¦¬ê³  ë‹¹ì‹ ì€ êµ¬ê¸€ì—ì„œ ë°œí‘œëœ Open Soruce LLM ëª¨ë¸ì…ë‹ˆë‹¤'),\n",
    "   ('user', '{input}'),\n",
    "  \n",
    "])\n",
    "\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "answer = chain.invoke({'input' : 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜'})\n",
    "\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
