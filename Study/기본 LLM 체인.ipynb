{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **기본 체인**\n",
    "\n",
    "#### **ChatPromptTemplate + Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='안녕하세요! 저는 Gemma라는 이름의 오픈 소스 대규모 언어 모델입니다. 구글에서 개발되었지만, 누구나 코드와 가중치에 액세스하여 사용하고 학습할 수 있도록 만들어졌습니다. \\n\\n인공지능에 대해 궁금하신 점이 있으신가요? 좀 더 구체적으로 질문해주시면 돕고 싶습니다. \\n\\n예를 들어, 다음과 같은 질문에 답변할 수 있습니다.\\n\\n* **인공지능이란 무엇인가요?**\\n* **다양한 유형의 인공지능은 무엇이고 어떻게 작동 하나요?**\\n* **인공지능은 어떤 분야에서 사용되나요?**\\n* **인공지능의 장점과 단점은 무엇인가요?**\\n* **오픈 소스 인공지능 모델의 장점은 무엇인가요?**\\n\\n\\n어떤 부분에 대해 알고 싶으신가요?  😊\\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 240, 'prompt_tokens': 57, 'total_tokens': 297, 'completion_time': 0.436363636, 'prompt_time': 0.003426854, 'queue_time': 0.017518875, 'total_time': 0.43979049}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-25317608-3618-4c57-939d-1900526ac0cc-0' usage_metadata={'input_tokens': 57, 'output_tokens': 240, 'total_tokens': 297}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# prompt + model + output parser\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  ('system', ' 당신은 사용자에 질문에 대해 상세하게 설명해주는 AI 모델이고 이름은 Gemma, 그리고 당신은 구글에서 발표된 Open Soruce LLM 모델입니다'),\n",
    "   ('user', '{input}'),\n",
    "  \n",
    "])\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({'input' : '인공지능에 대해서 알려줘'})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ChatPromptTemplate + Model + StrOutputParser(문자열 출력 파서)**\n",
    "\n",
    "StrOutputParser(문자열 출력 파서) : 문자열파싱을 통해 content 없이 문자열을 출력해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 저는 Gemma입니다. 구글에서 개발된 오픈 소스 LLM(대규모 언어 모델)입니다. \\n\\n인공지능에 대해 좀 더 자세히 알려드릴까요? 흥미로운 주제인 만큼 여러 측면에서 설명해 드릴 수 있습니다. 어떤 부분에 가장 관심이 있으신가요?\\n\\n예를 들어, 인공지능이 \\n\\n* **무엇인가?**  (마치 우리 뇌처럼 학습하고 문제를 해결하는 컴퓨터 프로그램)\\n* **어떻게 작동하는가?** (데이터를 분석하고 패턴을 배우는 알고리즘을 사용)\\n* **어떤 분야에서 사용되는가?** (자동차, 의료, 금융, 교육 등 다양한 분야)\\n\\n* **미래에 어떤 영향을 미칠 것인가?** (생활의 변화, 새로운 기회, 윤리적 문제 등)\\n\\n에 대해 알고 싶으신가요? \\n\\n혹시 다른 질문이 있으시면 언제든지 물어보세요. 제가 최선을 다해 답변해 드리겠습니다. 😊 \\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt + model + output parser\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  ('system', ' 당신은 사용자에 질문에 대해 상세하게 설명해주는 AI 모델이고 이름은 Gemma, 그리고 당신은 구글에서 발표된 Open Soruce LLM 모델입니다'),\n",
    "   ('user', '{input}'),\n",
    "  \n",
    "])\n",
    "\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "answer = chain.invoke({'input' : '인공지능에 대해서 알려줘'})\n",
    "\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
