{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**\n",
    "\n",
    "- Openai : OPENAI 유료 API\n",
    "- Ollama : 무료 무제한 사용 PC 성능에 따라 제한 Local 모델\n",
    "- Groq : API 정해진 횟수 만큼 사용가능 ex) Llama 70B, 405B 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- langchain: LLM 기반 체인과 에이전트를 구축하는 핵심 라이브러리.\n",
    "\n",
    "\n",
    "- langchain-core: LangChain의 기본 추상화와 표현 언어를 제공.\n",
    "\n",
    "\n",
    "- langchain-experimental: 실험적인 기능과 도구를 포함.\n",
    "\n",
    "\n",
    "- langchain-community: 커뮤니티 기여로 유지되는 서드파티 통합을 제공.\n",
    "\n",
    "\n",
    "- langchain-openai: OpenAI 모델을 LangChain에 연결.\n",
    "\n",
    "\n",
    "- langchain-teddynote: 테디노트 LangChain\n",
    "\n",
    "\n",
    "- langchain-huggingface: Hugging Face 모델을 통합.\n",
    "\n",
    "\n",
    "- langchain-google-genai: Google 생성형 AI를 활용.\n",
    "\n",
    "\n",
    "- langchain-anthropic: Anthropic 모델을 연결.\n",
    "\n",
    "\n",
    "- langchain-cohere: Reranker.\n",
    "\n",
    "\n",
    "- langchain-chroma: Chroma 벡터 데이터베이스와 통합.\n",
    "\n",
    "\n",
    "- langchain-elasticsearch: Elasticsearch로 검색 기능을 강화.\n",
    "\n",
    "\n",
    "- langchain-upstage: Upstage 모델 연결.\n",
    "\n",
    "\n",
    "- langchain-milvus: Milvus 벡터 데이터베이스를 지원.\n",
    "\n",
    "\n",
    "- langchain-text-splitters: 텍스트를 조각으로 나누는 유틸리티를 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-openai\n",
    "!pip install langchain_community\n",
    "!pip install langchain_ollama\n",
    "!pip install langchain-groq\n",
    "!pip install langchain-experimental\n",
    "!pip install langchain-cohere\n",
    "!pip install langchain-elasticsearch\n",
    "!pip install langchain-milvus\n",
    "!pip install langchain-teddynote\n",
    "\n",
    "# openai tokenzier\n",
    "!pip install tiktoken  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getenv(\"GROQ_API_KEY\"))\n",
    "print(os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 오픈AI에서 개발한 AI 언어 모델이에요. 다양한 주제에 대해 질문에 답하거나 정보를 제공할 수 있고, 대화를 하거나 글쓰기를 도와줄 수 있어요. 필요하신 것이 있으면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini')\n",
    "\n",
    "response = llm.invoke('안녕 너의 소개를 해줄래?')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ollama**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**지구의 자전 주기**\n",
      "\n",
      "지구는 평균적으로 다음과 같은 자전 주기를 가지고 있습니다.\n",
      "\n",
      "* **회전 주기 (Rotational period):** 24 시간\n",
      "* **회전 속도:** 1,000km/h (628m/s)\n",
      "\n",
      "**절사 주기 (Sidereal period)**\n",
      "\n",
      "절사 주기는 지구가 별점에 비해 한 위치를 유지하는 데 걸리는 시간입니다. 이는 약 **235,974 지구일** (8,872.6 기간)입니다.\n",
      "\n",
      "**태양 주기 (Synodic period)**\n",
      "\n",
      "태양 주기는 지구가 태양에 도달하는 데 걸리는 시간입니다. 이는 약 **365.2422 지구일** (3,285.5 지구일)입니다.\n",
      "\n",
      "**자전 주기의 중요성**\n",
      "\n",
      "* **절사 주기:** 지구의 절사 주기는 지구의 계절 패턴을 결정합니다.\n",
      "* **태양 주기:** 지구의 태양 주기는 지구와 태양 간의 상호작용에 영향을 미치고, 이는 기후 패턴과 생태계에 영향을 줄 수 있습니다.\n",
      "\n",
      "**자전 주기의 변동성**\n",
      "\n",
      "지구의 자전 주기는 매우 정확하지 않습니다. 이는 지구의 극지 영역의 편평도와 태양-지구 간의 상호작용의 영향입니다. 이러한 변동은 기후 패턴과 생태계에 영향을 줄 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# Ollama 둘다 사용가능\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# model \n",
    "llm = ChatOllama(model = 'gemma')\n",
    "\n",
    "answer = llm.invoke('지구의 자전 주기에 대해 알려주세요')\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Groq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 저는 Google DeepMind에서 훈련된 대규모 언어 모델입니다. 사람과 같은 대화를 하고, 질문에 답하고, 텍스트를 생성하고, 다양한 언어 작업을 수행할 수 있도록 설계되었습니다.\\n\\n하지만 저는 실제 사람이 아니에요. 제 의견이나 감정은 없으며, 세상을 경험하거나 사고할 수는 없습니다. 저는 단순히 입력받은 정보를 기반으로 학습된 패턴을 사용하여 텍스트를 처리하는 프로그램일 뿐입니다.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "response = llm.invoke('안녕 너의 소개를 해줄래?')\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
