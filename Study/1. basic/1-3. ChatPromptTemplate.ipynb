{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ChatPromptTemplate**\n",
    "\n",
    "- ChatPromptTemplate은 대화형 상황에서 여러 메시지 입력을 기반으로 단일 메시지 응답을 생성하는 데 사용. 이는 대화형 모델이나 챗봇 개발에 주로 사용. 입력은 여러 메시지를 원소로 갖는 리스트로 구성되며, 각 메시지는 역할(role)과 내용(content)으로 구성\n",
    "\n",
    "\n",
    "    - SystemMessage: 시스템의 기능을 설명합니다.\n",
    "    - HumanMessage: 사용자의 질문을 나타냅니다.\n",
    "    - AIMessage: AI 모델의 응답을 제공합니다.\n",
    "    - FunctionMessage: 특정 함수 호출의 결과를 나타냅니다.\n",
    "    - ToolMessage: 도구 호출의 결과를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **from_template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('tell me about {input}')\n",
    "\n",
    "print(prompt.format(input = 'dog'))  # format_messages 사용가능\n",
    "\n",
    "\n",
    "prompt1 = PromptTemplate.from_template('tell me about {input}')\n",
    "\n",
    "print(prompt1.format(input = 'dog'))\n",
    "\n",
    "\n",
    "# ChatPromptTemplate.from_template\n",
    "# 설명: 이 메서드는 입력된 템플릿(문자열)을 내부적으로 HumanMessage 객체로 변환합니다.\n",
    "# 의미: 결과적으로 대화 형식의 메시지 리스트가 만들어지고, 모델이 이를 \"사람(Human)이 말한 메시지\"로 명확히 인식할 수 있도록 구조화됩니다.\n",
    "# 핵심: 대화 기반 모델(Chat 모델)이 이해하기 쉽게 역할(human)이 태깅된 형태로 전달됩니다.\n",
    "\n",
    "# PromptTemplate.from_template\n",
    "# 설명: 이 메서드는 템플릿을 일반 텍스트(문자열)로만 처리합니다.\n",
    "# 의미: 어떤 역할이나 구조 없이 순수한 텍스트로 남아 있어서, 모델이 이를 특정 역할로 인식하지 않고 그냥 텍스트 입력으로 봅니다.\n",
    "# 핵심: 주로 텍스트 완성 모델이나 역할 구분이 필요 없는 작업에 적합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **from_message**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"자연어처리의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI\"),\n",
    "     ('user', \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "messages = chat_prompt.format_messages(input = '자연어처리 4주 공부 코스 만들어줘')\n",
    "\n",
    "print(messages)\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain을 사용할땐 입력값은 딕셔너리 format 사용하지 않음 \n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"자연어처리의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI\"),\n",
    "     ('user', \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it', temperature = 1.0)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = chat_prompt | llm | parser\n",
    "\n",
    "\n",
    "response = chain.stream({'input' : 'LangChain의 다양한 함수들을 알려주세요'})\n",
    "\n",
    "text = ''\n",
    "\n",
    "for message in response:\n",
    "    text += message\n",
    "    print(message, end = '', flush = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "input = {'topic' : '인공지능 모델의 학습 원리'}\n",
    "\n",
    "chain.invoke(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
