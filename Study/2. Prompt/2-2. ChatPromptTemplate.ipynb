{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ChatPromptTemplate**\n",
    "\n",
    "- ChatPromptTemplate은 대화형 상황에서 여러 메시지 입력을 기반으로 단일 메시지 응답을 생성하는 데 사용. 이는 대화형 모델이나 챗봇 개발에 주로 사용. \n",
    "- 입력은 여러 메시지를 원소로 갖는 리스트로 구성되며, 각 메시지는 역할(role)과 내용(content)으로 구성\n",
    "\n",
    "\n",
    "    - `SystemMessage` : 시스템의 설정 메세지\n",
    "    - `HumanMessage` : 사용자의 입력 메세지\n",
    "    - `AIMessage` : AI 모델의 답변\n",
    "    - `FunctionMessage` : 특정 함수 호출의 결과\n",
    "    - `ToolMessage` : 도구 호출의 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ChatPromptTemplate.from_template**\n",
    "- 설명: 이 메서드는 입력된 템플릿(문자열)을 내부적으로 HumanMessage 객체로 변환함\n",
    "- 의미: 결과적으로 대화 형식의 메시지 리스트가 만들어지고, 모델이 이를 \"사람(Human)이 말한 메시지\"로 명확히 인식할 수 있도록 구조화\n",
    "- 핵심: 대화 기반 모델(Chat 모델)이 이해하기 쉽게 역할(human)이 태깅된 형태로 전달\n",
    "\n",
    "### **PromptTemplate.from_template**\n",
    "- 설명: 이 메서드는 템플릿을 일반 텍스트(문자열)로만 처리함\n",
    "- 의미: 어떤 역할이나 구조 없이 순수한 텍스트로 남아 있어서, 모델이 이를 특정 역할로 인식하지 않고 그냥 텍스트 입력으로 봄\n",
    "- 핵심: 주로 텍스트 완성 모델이나 역할 구분이 필요 없는 작업에 적합함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **from_template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('tell me about {input}')\n",
    "\n",
    "print(prompt.format(input = 'dog'))  # format_messages 사용가능\n",
    "\n",
    "\n",
    "prompt1 = PromptTemplate.from_template('tell me about {input}')\n",
    "\n",
    "print(prompt1.format(input = 'dog'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **from_message**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='자연어처리의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI', additional_kwargs={}, response_metadata={}), HumanMessage(content='자연어처리 4주 공부 코스 만들어줘', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'## AI 자연어처리 4주 공부 코스: LLM 전문가를 위한 탄탄한 기초 다지기\\n\\n**목표**: 이 코스를 통해 LLM(Large Language Model)의 기본 개념, 작동 원리, 활용 방법 등에 대한 이해를 높이고, 자연어처리 분야의 핵심 기술들을 익혀 LLM 전문가로서의 기반을 다십니다. \\n\\n**대상**: 자연어처리에 대한 기본 지식이 있는 사람, 또는 LLM에 대한 이해를 높이고 싶어하는 모든 사람\\n\\n**필요한 준비물**:\\n\\n* 컴퓨터 및 인터넷 연결\\n* 노트 및 필기구\\n* Python 기초 지식 (선택 사항)\\n\\n**코스 구성**:\\n\\n**주차 1: 자연어처리의 기초와 LLM 개념**\\n\\n* **Day 1**: 자연어처리 (NLP)란 무엇인가? \\n    * NLP의 역사와 발전 과정\\n    * NLP의 주요 분야 (텍스트 분류, 감정 분석, 번역 등)\\n    * NLP 솔루션의 실제 활용 사례\\n* **Day 2**: LLM (Large Language Model) 소개\\n    * Transformer Architectures와 LLM의 혁신\\n    * 대규모 데이터 학습과 LLM의 성능 향상\\n    * 유명 LLM 모델들 (GPT-3, BERT, LaMDA 등)\\n* **Day 3**: LLM의 작동 원리\\n    * 자연어 처리 Pipeline\\n    * Embedding, Attention, Decoder\\n    * 텍스트 생성 및 예측 방법\\n* **Day 4**: LLM의 기회와 과제\\n    * LLM의 윤리적 쟁점 (편견, 오용, 사실 확인 등)\\n    * LLM 기술의 미래 전망\\n\\n**주차 2: LLM 기반 텍스트 분석 및 처리**\\n\\n* **Day 1**: 텍스트 분류 및 분할\\n    * Naive Bayes, SVM, Logistic Regression\\n    * Sequence Labeling (NER, POS Tagging)\\n* **Day 2**: 감정 분석 및 의도 파악\\n    * 감정 분류, 감정 극단성 분석\\n    * 의도 인식 및 응답 생성\\n* **Day 3**: 텍스트 요약 및 추출\\n    * Extractive Summarization, Abstractive Summarization\\n    * Keyphrase Extraction\\n* **Day 4**: 의사소통 챗봇 개발\\n    * Rule-based Chatbot, Retrieval-based Chatbot\\n    * Generative Chatbot (LLM 기반)\\n\\n**주차 3: LLM 기반 텍스트 생성 및 번역**\\n\\n* **Day 1**: 자연어 생성 (Text Generation)\\n    * GPT-3 및 다른 LLM 모델 활용\\n    * Creative Writing, Story Generation, Dialogue Generation\\n* **Day 2**: 기계 번역 (Machine Translation)\\n    * Transformer 모델과 번역 기술\\n    * 번역 서비스 (Google Translate, DeepL 등)\\n* **Day 3**: 코드 생성 (Code Generation)\\n    * Codex와 같은 코드 생성 LLM\\n    * 코드 완성, 코드 이해 및 설명\\n* **Day 4**: 다국어 처리 및 개체 지식\\n\\n**주차 4: LLM 응용 및 미래 전망**\\n\\n* **Day 1**: LLM 기반 상품 개발 (예시: 교육, 의료, 마케팅)\\n    * 사례 분석 및 성공 전략\\n* **Day 2**: LLM 연구 동향 및 트렌드\\n    * Multimodality, Reasoning, Common Sense\\n* **Day 3**: LLM 윤리 및 사회적 영향\\n    * 편견 해소, 정보 왜곡, 신뢰성 문제\\n* **Day 4**: LLM 전문가로서의 미래 전망\\n\\n**학습 자료**:\\n\\n* 온라인 강의 (Coursera, edX, fast.ai)\\n* 책 (Speech and Language Processing by Jurafsky & Martin)\\n* 블로그 및 논문 (ACL Anthology, arXiv)\\n* 오픈소스 라이브러리 및 프레임워크 (HuggingFace, OpenAI API)\\n\\n\\n**성공적인 코스 완료를 위한 팁**:\\n\\n* 매일 꾸준히 학습하고 실습하기\\n* 온라인 커뮤니티 활용하여 질문하고 토론하기\\n* 개인 프로젝트를 진행하여 LLM 기술을 적용하고 경험쌓기\\n\\n이 코스를 통해 LLM의 세계를 탐험하고, 자연어처리 분야의 핵심 기술들을 폭넓게 이해하며 LLM 전문가로서의 첫걸음을 시작하세요!\\n\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 단일 변수\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"자연어처리의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI\"),\n",
    "     ('user', \"{input}\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(input = '자연어처리 4주 공부 코스 만들어줘')\n",
    "\n",
    "print(messages)\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "response = llm.invoke(messages)  # '자연어처리 4주 공부 코스 만들어줘' 그대로 넣어도 됨\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 복수 변수 \n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{answer}의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI\"),\n",
    "     ('user', \"{input}\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(answer = '인공지능',\n",
    "                                       input = '자연어 처리를 공부하는 방법에 대해서 알려줘')\n",
    "\n",
    "print(messages)\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it', max_tokens = 256)\n",
    "\n",
    "response = llm.invoke(messages)  # '자연어처리 4주 공부 코스 만들어줘' 그대로 넣어도 됨\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 복수 변수 체인\n",
    "# Chain을 사용할땐 입력값은 딕셔너리 format 사용하지 않음 \n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{answer}의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI\"),\n",
    "     ('user', \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "chain = chat_prompt | llm\n",
    "\n",
    "response = chain.invoke({'answer' : '인공지능', 'input' : '자연어 처리를 공부하는 방법에 대해서 알려줘'})  \n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성함함\n",
    "# 1개의 변수만 가지고 있을땐 딕셔너리 형태로 입력하지 않아도 됨.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke('인공지능 모델의 학습 원리')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
