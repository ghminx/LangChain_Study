{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ChatPromptTemplate**\n",
    "\n",
    "- ChatPromptTemplate은 대화형 상황에서 여러 메시지 입력을 기반으로 단일 메시지 응답을 생성하는 데 사용. 이는 대화형 모델이나 챗봇 개발에 주로 사용. 입력은 여러 메시지를 원소로 갖는 리스트로 구성되며, 각 메시지는 역할(role)과 내용(content)으로 구성\n",
    "\n",
    "\n",
    "    - SystemMessage: 시스템의 기능을 설명합니다.\n",
    "    - HumanMessage: 사용자의 질문을 나타냅니다.\n",
    "    - AIMessage: AI 모델의 응답을 제공합니다.\n",
    "    - FunctionMessage: 특정 함수 호출의 결과를 나타냅니다.\n",
    "    - ToolMessage: 도구 호출의 결과를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **from_template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: tell me about dog\n",
      "tell me about dog\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('tell me about {input}')\n",
    "\n",
    "print(prompt.format(input = 'dog'))  # format_messages 사용가능\n",
    "\n",
    "\n",
    "prompt1 = PromptTemplate.from_template('tell me about {input}')\n",
    "\n",
    "print(prompt1.format(input = 'dog'))\n",
    "\n",
    "\n",
    "# ChatPromptTemplate.from_template\n",
    "# 설명: 이 메서드는 입력된 템플릿(문자열)을 내부적으로 HumanMessage 객체로 변환합니다.\n",
    "# 의미: 결과적으로 대화 형식의 메시지 리스트가 만들어지고, 모델이 이를 \"사람(Human)이 말한 메시지\"로 명확히 인식할 수 있도록 구조화됩니다.\n",
    "# 핵심: 대화 기반 모델(Chat 모델)이 이해하기 쉽게 역할(human)이 태깅된 형태로 전달됩니다.\n",
    "\n",
    "# PromptTemplate.from_template\n",
    "# 설명: 이 메서드는 템플릿을 일반 텍스트(문자열)로만 처리합니다.\n",
    "# 의미: 어떤 역할이나 구조 없이 순수한 텍스트로 남아 있어서, 모델이 이를 특정 역할로 인식하지 않고 그냥 텍스트 입력으로 봅니다.\n",
    "# 핵심: 주로 텍스트 완성 모델이나 역할 구분이 필요 없는 작업에 적합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **from_message**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='자연어처리의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI', additional_kwargs={}, response_metadata={}), HumanMessage(content='자연어처리 4주 공부 코스 만들어줘', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'## AI 자연어처리 4주 공부 코스: LLM 전문가를 위한 길잡이\\n\\n**이 코스는 LLM (Large Language Model)에 대한 이해를 넓히고 자연어처리 분야 전문가가 되기 위한 기반을 마련하는 것을 목표로 합니다.** \\n\\n**각 주차는 다음과 같은 주제를 다루며, 각 주차별 학습 목표와 추천 자료를 제공합니다.**\\n\\n**1주차: 자연어처리 개론 및 기초**\\n\\n* **학습 목표:** 자연어처리의 정의, 역사, 분야 및 주요 기술 이해\\n* **내용:**\\n    * 자연어처리란 무엇인가?\\n    * 자연어처리의 역사와 발전\\n    * 자연어처리의 주요 분야 (텍스트 분류, 챗봇, 번역, 텍스트 요약 등)\\n    * 기본적인 자연어처리 기술 (문장 구조 분석, 사전,STEM 등)\\n* **추천 자료:**\\n    * Stanford NLP Course: https://web.stanford.edu/class/cs224n/\\n    * Natural Language Processing with Python (Book): https://www.nltk.org/book/\\n    * NLTK 자바스크립트 Tutorial: https://www.nltk.org/book/ch01.html\\n\\n**2주차: 텍스트 분석 및 특징 추출**\\n\\n* **학습 목표:** 텍스트 데이터에서 의미있는 정보를 추출하는 방법 이해\\n* **내용:**\\n    * Bag-of-Words (BoW) 모델\\n    * TF-IDF\\n    * Word Embeddings (Word2Vec, GloVe, FastText)\\n    * 텍스트 벡터화 및 군집 분석\\n* **추천 자료:**\\n    * scikit-learn: https://scikit-learn.org/stable/\\n    * Gensim: https://radimrehurek.com/gensim/\\n    * Word2Vec Tutorial: https://www.tensorflow.org/tutorials/text/word2vec\\n\\n**3주차: LLM 인트로 & 구조**\\n\\n* **학습 목표:** LLM의 개념, 구조, 학습 방법 이해\\n* **내용:**\\n    * Transformer 구조 (Encoder-Decoder, Attention Mechanism)\\n    * BERT, GPT, LaMDA 등 대표적인 LLM 소개\\n    * LLM의 학습 방법 (Supervised Learning, Self-Supervised Learning, Transfer Learning)\\n* **추천 자료:**\\n    * The Illustrated Transformer: https://jalammar.github.io/illustrated-transformer/\\n    * BERT Paper: https://arxiv.org/abs/1810.04805\\n    * GPT-3 Paper: https://openai.com/blog/gpt-3/\\n\\n**4주차: LLM 응용 및 프로젝트**\\n\\n* **학습 목표:** LLM을 활용한 실제 응용 사례 이해 및 프로젝트 구현\\n* **내용:**\\n    * 텍스트 생성 (스토리, 시, 코드 등)\\n    * 챗봇 개발\\n    * 번역 및 요약\\n    * 질의응답 시스템 구축\\n* **추천 자료:**\\n    * Hugging Face Transformers: https://huggingface.co/transformers/index.html\\n    * OpenAI API: https://platform.openai.com/docs/api-reference\\n\\n**코스 진행 팁:**\\n\\n* 각 주차별 학습 내용을 꼼꼼히 이해하고, 실습을 통해 LLM을 직접 경험하는 것이 중요합니다.\\n* 온라인 커뮤니티 (Stack Overflow, Reddit)를 활용하여 질문하고 다른 학습자들과 교류하는 데 도움이 됩니다.\\n* 스터디 그룹을 만들어 함께 공부하면 더욱 효과적인 학습이 가능합니다.\\n* LLM 관련 최신 연구 논문을 읽고 발전 추세를 파악하는 것도 좋습니다.\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"자연어처리의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI\"),\n",
    "     ('user', \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "messages = chat_prompt.format_messages(input = '자연어처리 4주 공부 코스 만들어줘')\n",
    "\n",
    "print(messages)\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## LangChain: LLM을 훨씬 강력하게 활용하는 다양한 함수들\n",
      "\n",
      "안녕하세요! 저는 자연어 처리 전문 AI입니다. LangChain은 Large Language Models (LLM)의 잠재력을 끌어내기 위해 설계된 툴킷이고, 그 안에는 LLM을 더 유능하게 사용할 수 있는 다양한 함수들이 있습니다. \n",
      "\n",
      "LangChain 함수를 쉽게 이해하기 위해서는 \"LLM은 강력한 도구지만 혼자서 모든 일을 해내기는 어렵다\"는 생각으로 시작해야 합니다. LangChain은 LLM에 특수한 처리가 필요한 정보를 제공하거나, LLM의 결과를 효율적으로 활용하기 위한 구조적 돕기 역할을 합니다.\n",
      "\n",
      "**LangChain을 사용하는 핵심 함수**들을 몇 가지 카테고리로 나누어 설명해 드릴게요.\n",
      "\n",
      "**1. LLM과의 상호작용:**\n",
      "\n",
      "* **`LLMChain`**: 가장 기본적인 함수입니다. LLM에게 질문을 하고 그 응답을 받는 시스템을 구축할 때 사용됩니다. \n",
      "\n",
      "* **`LLMTool`**: LLM에게 외부 도구를 활용하도록 명령할 수 있습니다. 예를 들어, 웹 검색 엔진에 질문을 던져서 결과를 LLM에 입력하도록 할 수 있습니다.\n",
      "\n",
      "* **`PromptTemplate`**: LLM에게 입력되는 질문(prompts)을 정의하고 변수를 사용해서 유연하게 조절할 수 있습니다.\n",
      "\n",
      "**2. 메모리 관리:**\n",
      "\n",
      "* **`ConversationChain`**: LLM과 지속적인 대화를 하도록 설정합니다. 이전 대화 내용을 기억하고 따라가는 능력이 있어서 자연스러운 대화를 구현하는 데 유용합니다.\n",
      "\n",
      "* **`Memory`**: 명확하게 메모리 저장 및 불러오기 기능을 제공합니다. \n",
      "\n",
      "**3. 데이터 조작 및 분석:**\n",
      "\n",
      "* **`RetrievalQAChain`**: 데이터베이스 등 저장된 자료를 기반으로 질문에 답할 수 있도록 구성합니다. \n",
      "* **`VectorStore`**: 텍스트 데이터를 고차원 벡터로 변환하여 검색 및 유사도 파악에 용이하게 만듭니다. 이를 통해 관련 정보를 효율적으로 추출할 수 있습니다.\n",
      "\n",
      "**4. 다양한 모델 연동:**\n",
      "\n",
      "* **`OpenAI`**: OpenAI의 API를 통해 GPT-3와 같은 모델을 활용합니다.\n",
      "* **`HuggingFace`**: HuggingFace Hub에서 제공하는 다양한 open-source LLM과 연동 가능합니다.\n",
      "\n",
      "\n",
      "LangChain의 함수들을 독립적으로 사용하거나 다양하게 조합하여 당신의 LLM 기반 프로젝트에 맞는 시스템을 구축할 수 있습니다. \n",
      "\n",
      "혹시 더 궁금한 점이 있거나 특정 기능에 대해 자세히 알고 싶으면  말씀해주세요!"
     ]
    }
   ],
   "source": [
    "# Chain을 사용할땐 입력값은 딕셔너리 format 사용하지 않음 \n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"자연어처리의 전문가로서 LLM에 대해서 잘 설명해줄수있는 AI\"),\n",
    "     ('user', \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it', temperature = 1.0)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = chat_prompt | llm | parser\n",
    "\n",
    "response = chain.stream({'input' : 'LangChain의 다양한 함수들을 알려주세요'})\n",
    "\n",
    "text = ''\n",
    "\n",
    "for message in response:\n",
    "    text += message\n",
    "    print(message, end = '', flush = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능(AI) 모델 학습은 사람이 학습하는 것처럼,  데이터를 통해 지식을 배우고 능력을 향상시키는 과정이에요! 🤖\\n\\n마치 아이가 그림을 보고 \\'사과\\'라는 것을 배우듯, AI 모델도 다양한 데이터를 분석하고 패턴을 파악해서 새로운 정보를 학습합니다. 🍎\\n\\n대부분의 AI 모델 학습은 **지도학습**, **비지도학습**, **강화학습** 세 가지 방법으로 이뤄집니다.\\n\\n* **지도학습:** 老师처럼! 이미 정답이 있는 데이터를 모델에게 주고, 답을 맞히도록 가르칩니다. 예를 들어, 고양이 사진과 개 사진을 막이 보고 \"고양이\", \"개\"라는 라벨을 붙여서 모델에게 보여주면, 모델은 차이를 배우고 새로운 사진을 보고 정답을 맞히게 됩니다. 😻🐶\\n* **비지도학습:** 스스로 찾아내는 능력! 정답이 없는 데이터를 주고, 모델 스스로 패턴을 찾고 그룹화하도록 합니다. 예를 들어, 여러 개의 사람 사진만 주면, 모델 스스로 연령, 성별 등의 특징으로 사람들을 분류할 수 있습니다. 👨\\u200d👩\\u200d👧\\u200d👦\\n* **강화학습:** 보상을 받으면 더 배우는 방식! 모델이 선택을 하고 결과가 나오면, 해당 선택에따라 보상이나 처벌을 받습니다. 예를 들어 게임을 하는 AI 모델이 점수를 높이면 보상을 받고, 점수가 낮아지면 처벌을 받아 더 좋은 판단을 하도록 강도합니다. 🌟\\n\\n이처럼 AI 모델은 데이터를 기반으로 학습하여 다양한 작업을 수행할 수 있습니다! 😊  더 복잡하고 강력한 모델이 개발되면서, 우리 삶을 더욱 풍요롭게 만들어 갈 것입니다. ✨\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 462, 'prompt_tokens': 29, 'total_tokens': 491, 'completion_time': 0.84, 'prompt_time': 0.002259865, 'queue_time': 0.018071493, 'total_time': 0.842259865}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-195d6d4f-0207-4001-969d-5da38b6ee2b4-0', usage_metadata={'input_tokens': 29, 'output_tokens': 462, 'total_tokens': 491})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "# 1개의 변수만 가지고 있을땐 딕셔너리 형태로 입력하지 않아도 됨.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke('인공지능 모델의 학습 원리')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
