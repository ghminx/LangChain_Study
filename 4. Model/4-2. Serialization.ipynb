{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ì§ë ¬í™”(Serialization)**\n",
    "\n",
    "- ëª¨ë¸ì„ ì €ì¥ ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •\n",
    "\n",
    "#### **ëª©ì **\n",
    "- ëª¨ë¸ ì¬ì‚¬ìš© (ì¬í›ˆë ¨ ì—†ì´)\n",
    "- ëª¨ë¸ ë°°í¬ ë° ê³µìœ  ìš©ì´\n",
    "- ê³„ì‚° ë¦¬ì†ŒìŠ¤ ì ˆì•½\n",
    "\n",
    "#### **ì¥ì **\n",
    "- ë¹ ë¥¸ ëª¨ë¸ ë¡œë”©\n",
    "- ë²„ì „ ê´€ë¦¬ ê°€ëŠ¥\n",
    "- ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥\n",
    "- ëª¨ë¸ ì§ë ¬í™”ëŠ” AI ê°œë°œ ë° ë°°í¬ ê³¼ì •ì—ì„œ ì¤‘ìš”í•œ ë‹¨ê³„ë¡œ, íš¨ìœ¨ì ì¸ ëª¨ë¸ ê´€ë¦¬ì™€ ì¬ì‚¬ìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGroq: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{fruit}ì˜ ìƒ‰ìƒì´ ë¬´ì—‡ì…ë‹ˆê¹Œ?\")\n",
    "\n",
    "# ì§ë ¬í™”ê°€ ì—¬ë¶€ í™•ì¸\n",
    "print(f\"ChatGroq: {ChatGroq.is_lc_serializable()}\")\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "# ì²´ì¸ ì§ë ¬í™” ì—¬ë¶€ í™•ì¸\n",
    "chain.is_lc_serializable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chain ì§ë ¬í™”(dumps, dumpd)**\n",
    "\n",
    "- ì§ë ¬í™” ê°€ëŠ¥í•œ ê°ì²´ë¥¼ Dict Or JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ \n",
    "\n",
    "#### **ì§ë ¬í™” ë°©ë²•**\n",
    "ê°ì²´ì˜ ì†ì„± ë° ë°ì´í„°ë¥¼ í‚¤-ê°’ ìŒìœ¼ë¡œ ì €ì¥í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜\n",
    "\n",
    "ì´ëŸ¬í•œ ì§ë ¬í™” ë°©ì‹ì€ ê°ì²´ë¥¼ ì‰½ê²Œ ì €ì¥í•˜ê³  ì „ì†¡í•  ìˆ˜ ìˆê²Œ í•˜ë©°, ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ê°ì²´ë¥¼ ì¬êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ í•¨\n",
    "\n",
    "\n",
    "`dumpd`: ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì§ë ¬í™”\n",
    "\n",
    "\n",
    "`dumps`: ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['fruit'], 'template': '{fruit}ì˜ ìƒ‰ìƒì´ ë¬´ì—‡ì…ë‹ˆê¹Œ?', 'template_format': 'f-string'}, 'name': 'PromptTemplate'}, 'last': {'lc': 1, 'type': 'constructor', 'id': ['langchain_groq', 'chat_models', 'ChatGroq'], 'kwargs': {'model_name': 'gemma2-9b-it', 'temperature': 0.7, 'groq_api_key': {'lc': 1, 'type': 'secret', 'id': ['GROQ_API_KEY']}, 'max_retries': 2, 'n': 1}, 'name': 'ChatGroq'}}, 'name': 'RunnableSequence'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.load import dumpd\n",
    "\n",
    "dumpd_chain = dumpd(chain)\n",
    "\n",
    "print(dumpd_chain)\n",
    "type(dumpd_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"runnable\", \"RunnableSequence\"], \"kwargs\": {\"first\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"prompt\", \"PromptTemplate\"], \"kwargs\": {\"input_variables\": [\"fruit\"], \"template\": \"{fruit}\\uc758 \\uc0c9\\uc0c1\\uc774 \\ubb34\\uc5c7\\uc785\\ub2c8\\uae4c?\", \"template_format\": \"f-string\"}, \"name\": \"PromptTemplate\"}, \"last\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain_groq\", \"chat_models\", \"ChatGroq\"], \"kwargs\": {\"model_name\": \"gemma2-9b-it\", \"temperature\": 0.7, \"groq_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"GROQ_API_KEY\"]}, \"max_retries\": 2, \"n\": 1}, \"name\": \"ChatGroq\"}}, \"name\": \"RunnableSequence\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.load import dumps\n",
    "\n",
    "dumps_chain = dumps(chain)\n",
    "\n",
    "print(dumps_chain)\n",
    "type(dumps_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save and Load**\n",
    "\n",
    "#### **Pickle**\n",
    "\n",
    "Pickle íŒŒì¼ì€ Python ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ í˜•íƒœë¡œ ì§ë ¬í™”í•˜ëŠ” í¬ë§·\n",
    "\n",
    "- Python ì „ìš© (ë‹¤ë¥¸ ì–¸ì–´ì™€ í˜¸í™˜ ë¶ˆê°€)\n",
    "- ëŒ€ë¶€ë¶„ì˜ Python ë°ì´í„° íƒ€ì… ì§€ì› (ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬, í´ë˜ìŠ¤ ë“±)\n",
    "- ê°ì²´ì˜ ìƒíƒœì™€ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ë³´ì¡´\n",
    "\n",
    "```bash\n",
    "pickle.dump(): ê°ì²´ë¥¼ íŒŒì¼ì— ì €ì¥\n",
    "pickle.load(): íŒŒì¼ì—ì„œ ê°ì²´ ë¡œë“œ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
       " 'kwargs': {'first': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "   'kwargs': {'input_variables': ['fruit'],\n",
       "    'template': '{fruit}ì˜ ìƒ‰ìƒì´ ë¬´ì—‡ì…ë‹ˆê¹Œ?',\n",
       "    'template_format': 'f-string'},\n",
       "   'name': 'PromptTemplate'},\n",
       "  'last': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain_groq', 'chat_models', 'ChatGroq'],\n",
       "   'kwargs': {'model_name': 'gemma2-9b-it',\n",
       "    'temperature': 0.7,\n",
       "    'groq_api_key': {'lc': 1, 'type': 'secret', 'id': ['GROQ_API_KEY']},\n",
       "    'max_retries': 2,\n",
       "    'n': 1},\n",
       "   'name': 'ChatGroq'}},\n",
       " 'name': 'RunnableSequence'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# pickleë¡œ ì €ì¥  ë°”ì´ë„ˆë¦¬ ëª¨ë“œì´ê¸° ë–„ë¬¸ì—(wb)\n",
    "with open('pickle/chain.pkl', 'wb') as f:\n",
    "    pickle.dump(dumpd_chain, f)\n",
    "\n",
    "# pickle ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open('pickle/chain.pkl', 'rb') as f:\n",
    "    pickle_chain = pickle.load(f)\n",
    "    \n",
    "pickle_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ê³¼ëŠ” ì¼ë°˜ì ìœ¼ë¡œ **ë¹¨ê°•** , **ì´ˆë¡** , **ë…¸ë‘** ìƒ‰ìƒìœ¼ë¡œ ì£¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "í•˜ì§€ë§Œ í’ˆì¢…ì— ë”°ë¼ ë‹¤ì–‘í•œ ìƒ‰ìƒì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \n",
      "\n",
      "* **ë¹¨ê°„ìƒ‰ ì‚¬ê³¼**:  í¬ë„ìƒ‰ ì‚¬ê³¼, ë²Œí”Œ ì‚¬ê³¼\n",
      "* **ì´ˆë¡ìƒ‰ ì‚¬ê³¼**: ê·¸ë¦° ì‚¬ê³¼\n",
      "* **ë…¸ë€ìƒ‰ ì‚¬ê³¼**: ê³¨ë“  ë”œë¦¬ì‹œì–´ìŠ¤ ì‚¬ê³¼\n",
      "\n",
      "ë“±ì´ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì§ë ¬í™”ëœ ì²´ì¸ì„ ë‹¤ì‹œ ë¡œë“œ\n",
    "from langchain_core.load import load\n",
    "\n",
    "# pickle ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open('pickle/chain.pkl', 'rb') as f:\n",
    "    pickle_chain = pickle.load(f)\n",
    "    \n",
    "chain_loaded = load(pickle_chain)\n",
    "response = chain_loaded.invoke('ì‚¬ê³¼')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ê³¼ì˜ ìƒ‰ìƒì€ ë‹¤ì–‘í•©ë‹ˆë‹¤. ğŸ\n",
      "\n",
      "ê°€ì¥ í”í•œ ìƒ‰ìƒì€ **ë¹¨ê°•**, **ì´ˆë¡ìƒ‰**, **ë…¸ë‘ìƒ‰**ì…ë‹ˆë‹¤. \n",
      "\n",
      "í•˜ì§€ë§Œ, ê·¸ ì™¸ì—ë„ **ì£¼í™©ìƒ‰**, **ì—°ë¶„í™ìƒ‰**, ** PURPLE** ë“±ì˜ ìƒ‰ìƒì„ ê°€ì§„ ì‚¬ê³¼ë„ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì–´ë–¤ ì‚¬ê³¼ì˜ ìƒ‰ìƒì´ ê°€ì¥ ì¢‹ë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”? ğŸ¤”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# jsonìœ¼ë¡œ ì €ì¥\n",
    "with open('pickle/chain.json', 'w') as f:\n",
    "    json.dump(dumpd_chain, f)\n",
    "\n",
    "# json ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open('pickle/chain.json', 'r') as f:\n",
    "    json_chain = json.load(f)\n",
    "    # langchain_core.load.load í•¨ìˆ˜ë¡œ ë¡œë“œ\n",
    "    chain_loaded_json = load(json_chain)\n",
    "    \n",
    "response = chain_loaded_json.invoke('ì‚¬ê³¼')\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
