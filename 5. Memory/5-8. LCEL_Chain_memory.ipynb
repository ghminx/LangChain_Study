{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LCEL Chain 메모리 추가**\n",
    "\n",
    "대화 내용 기억\n",
    "\n",
    "임의의 체인에 메모리를 추가하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_groq import ChatGroq\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 모델 정의\n",
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [   \n",
    "        ('system', 'You are a helpful AI assitants'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'),\n",
    "        ('user', '{input}')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': []}\n"
     ]
    }
   ],
   "source": [
    "# 대화 버퍼 메모리 생성, 메세지 반환 기능 활성화\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key = 'chat_history')  # 대화 기억을 저장하기 위한 메모리리\n",
    "print(memory.load_memory_variables({})) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnablePassthrough.assign` 사용\n",
    "\n",
    "`chat_history` 변수에 `memory.load_memory_variables` 함수의 결과를 할당하고, 이 결과에서 `chat_history` 키에 해당하는 값을 추출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables)  # memory.load_memory_variables를 실행시키기 위한 RunnableLambda\n",
    "    | itemgetter(\"chat_history\")  # 딕셔너리의 키값을 가져오기 위한 itemgetter(chat_history가 딕셔너리 형태기 때문에에)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '안녕하세요', 'chat_history': {'chat_history': []}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# itemgeter 안쓸때 \n",
    "runnable.invoke({'input' : '안녕하세요'})   # runnable.assign은 반드시 딕셔너리로 입력해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '안녕하세요', 'chat_history': []}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# itemgeter 쓸때\n",
    "runnable.invoke({'input' : '안녕하세요'})  # 'chat_history' : []  => 딕셔너리에서 키값을 가져와 리스트만 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 직장과 대학원까지 병행하시는군요. 정말 멋지고 힘든 일이겠네요.  \n",
      "\n",
      "어떤 분야를 공부하고 계신가요? 혹시 힘든 일이 있으신가요?  \n",
      "\n",
      "조금이라도 도움이 될 수 있으면 좋겠어요. 😊 💪\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chain 생성\n",
    "chain = runnable | prompt | llm\n",
    "\n",
    "# 응답 생성\n",
    "response = chain.invoke({'input' : \"안녕하세요 직장이고 대학원을 다니고 있어요\"})\n",
    "print(response.content)  # 생성된 응답을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='안녕하세요', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='안녕하세요! 👋  \\n\\n무엇을 도와드릴까요? 😊  \\n\\n저는 다양한 질문에 답하고, 텍스트를 생성하고, 번역을 도와드릴 수 있습니다.  \\n\\n궁금한 것이 있으시면 언제든지 물어보세요! 😊\\n', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아직 저장 안됨\n",
    "memory.load_memory_variables({}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터와 응답을 메모리에 저장 \n",
    "memory.save_context(\n",
    "    {\"user\": \"안녕하세요 직장이고 대학원을 다니고 있어요\"}, {\"ai\": response.content}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 👋  \\n\\n무엇을 도와드릴까요? 😊  \\n\\n저는 다양한 질문에 답하고, 텍스트를 생성하고, 번역을 도와드릴 수 있습니다.  \\n\\n궁금한 것이 있으시면 언제든지 물어보세요! 😊\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='안녕하세요 직장이고 대학원을 다니고 있어요', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 직장과 대학원까지 병행하시는군요. 정말 멋지고 힘든 일이겠네요.  \\n\\n어떤 분야를 공부하고 계신가요? 혹시 힘든 일이 있으신가요?  \\n\\n조금이라도 도움이 될 수 있으면 좋겠어요. 😊 💪\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리 저장기록 출력\n",
    "memory.load_memory_variables({})['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 기억해요! 직장과 대학원을 병행하고 계신다고 말씀하셨어요.  정말 멋지네요!  어떤 분야를 공부하고 계신가요? 😊\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 기억하고 있는지 확인\n",
    "response = chain.invoke({\"input\": \"제가 어떤걸 하고 있다고 말했는지 기억해?\"})\n",
    "# 답변을 출력합니다.\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **커스텀 ConversationChain 구현 예시**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, Runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ChatOpenAI 모델을 초기화합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 대화형 프롬프트를 생성합니다. 이 프롬프트는 시스템 메시지, 이전 대화 내역, 그리고 사용자 입력을 포함합니다.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 대화 버퍼 메모리를 생성하고, 메시지 반환 기능을 활성화합니다.\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "\n",
    "class MyConversationChain(Runnable):\n",
    "\n",
    "    def __init__(self, llm, prompt, memory, input_key=\"input\"):\n",
    "\n",
    "        self.prompt = prompt\n",
    "        self.memory = memory\n",
    "        self.input_key = input_key\n",
    "\n",
    "        self.chain = (\n",
    "            RunnablePassthrough.assign(\n",
    "                chat_history=RunnableLambda(self.memory.load_memory_variables)\n",
    "                | itemgetter(memory.memory_key)  # memory_key 와 동일하게 입력합니다.\n",
    "            )\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def invoke(self, query, configs=None, **kwargs):\n",
    "        answer = self.chain.invoke({self.input_key: query})\n",
    "        self.memory.save_context(inputs={\"human\": query}, outputs={\"ai\": answer})\n",
    "        return answer\n",
    "\n",
    "conversation_chain = MyConversationChain(llm, prompt, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 테디님! 만나서 반갑습니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"안녕하세요? 만나서 반갑습니다. 제 이름은 테디 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 테디입니다! 맞나요?'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"제 이름이 뭐라고요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Got it! I'll respond in English from now on. How can I assist you today?\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"앞으로는 영어로만 답변해주세요 알겠어요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Teddy.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"제 이름을 다시 한 번 말해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요? 만나서 반갑습니다. 제 이름은 테디 입니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요, 테디님! 만나서 반갑습니다. 어떻게 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='제 이름이 뭐라고요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='당신의 이름은 테디입니다! 맞나요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='앞으로는 영어로만 답변해주세요 알겠어요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Got it! I'll respond in English from now on. How can I assist you today?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='제 이름을 다시 한 번 말해주세요', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Teddy.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.memory.load_memory_variables({})[\"chat_history\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
