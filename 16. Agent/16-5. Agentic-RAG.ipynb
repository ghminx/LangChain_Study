{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645a0df7",
   "metadata": {},
   "source": [
    "### **에이전트를 활용한 RAG**\n",
    "\n",
    "- 문서 검색을 통해 최신 정보에 접근, 검색결과를 답변으로 제공하는 Agent \n",
    "- 질문에 따라 문서를 검색하여 답변 Or 인터넷 검색 도구를 활용하여 답변하는 에이전트 실습\n",
    "- Agent를 활용하여 RAG를 수행하는것이 Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a22754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily Search \n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(k = 3)\n",
    "\n",
    "# template = \"\"\" \n",
    "\n",
    "# 에스티이노베이션의 정보에 대해서 알려주세요   => 이렇게 템플릿 형식은 LLM이 있어야 가능\n",
    "\n",
    "# 주소 : \n",
    "# 전화번호 :\n",
    "# 홈페이지 :\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# 검색 \n",
    "search.invoke('에스티이노베이션이라는 회사에 대해서 알려주세요')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf442126",
   "metadata": {},
   "source": [
    "### **일반적인 RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abc97d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 페이지 수 : 23\n",
      "분리된 텍스트 페이지 수 : 43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='cfc4c74c-bfe6-4b1e-a6a6-ad7a351ed6e0', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': 'data/p_data.pdf', 'file_path': 'data/p_data.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 12}, page_content='SPRi AI Brief |  \\n2023-12월호\\n10\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\nKEY Contents\\n£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \\n이미지 모델의 3개 모델로 구성\\n∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \\n처리를 지원\\n∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \\n사내 소프트웨어 개발에 최적화\\n∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,'),\n",
       " Document(id='3e646208-df18-438c-be12-ac20af246f67', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': 'data/p_data.pdf', 'file_path': 'data/p_data.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 1}, page_content='▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\\n   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\\n   ▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망··········································· 12\\n   ▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································ 13\\n   ▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화···························································· 14\\n 3. 기술/연구\\n   ▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표······························································ 15\\n   ▹ 구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························ 16\\n   ▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수 ··········································· 17\\n   \\n 4. 인력/교육     \\n   ▹ 영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아······························· 18\\n   \\n   \\n \\nⅡ. 주요 행사\\n   ▹CES 2024 ····························································································································· 19'),\n",
       " Document(id='2613783b-701f-4d85-a20d-e676ee9817e7', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': 'data/p_data.pdf', 'file_path': 'data/p_data.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 12}, page_content='사내 소프트웨어 개발에 최적화\\n∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "loader = PyMuPDFLoader(\"data/p_data.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f'문서 페이지 수 : {len(docs)}')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "\n",
    "# text splitter1 문서 로드와 split를 한번에 수행 loader.load()를 생략 \n",
    "# split_text = loader.load_and_split(text_splitter = text_splitter)\n",
    "\n",
    "# text_splitter2 문서 로드와 split를 따로 수행\n",
    "split_text = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f'분리된 텍스트 페이지 수 : {len(split_text)}')\n",
    "\n",
    "# Embedding 모델 정의\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "# VectorStore 정의\n",
    "vector_store = FAISS.from_documents(split_text, embeddings)\n",
    "\n",
    "# Retriever 정의(기본 Retriever)\n",
    "retriever = vector_store.as_retriever(search_kwargs = {'k': 3})\n",
    "\n",
    "retriever.invoke(\"삼성전자가 개발한 생성형 AI 관련 내용을 문서에서 찾아줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cae4b0",
   "metadata": {},
   "source": [
    "### **Tools Retreiver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d098cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever = retriever,\n",
    "    name = 'pdf_search',\n",
    "    description = 'PDF 문서에서 정보를 검색하는 도구'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc8e8d8",
   "metadata": {},
   "source": [
    "### **Agent 도구 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0416bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7cb95d",
   "metadata": {},
   "source": [
    "### **Agent 생성**\n",
    "\n",
    "1. LLM 정의\n",
    "2. Prompt 정의\n",
    "\n",
    "chat_history : 멀티턴 대화 시 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9961bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Prompt 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"Make sure to use the `pdf_search` tool for searching information from the PDF document. \"\n",
    "            \"If you can't find the information from the PDF document, use the `search` tool for searching information from the web.\",\n",
    "        ),\n",
    "        # (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e480b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Agent 정의\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# AgentExecutor 정의\n",
    "agent_executor = AgentExecutor(agent = agent, tools = tools, verbose = False)  # verbose = False : 중간 단계 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eaba42",
   "metadata": {},
   "source": [
    "### **Run Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f06e9",
   "metadata": {},
   "source": [
    "#### **VectorDB에 없는 웹 검색이 필요한 질문**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6075db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[도구 호출]\n",
      "Tool: tavily_search_results_json\n",
      "query: 2024년 프로야구 플레이오프 진출 팀\n",
      "Log: \n",
      "Invoking: `tavily_search_results_json` with `{'query': '2024년 프로야구 플레이오프 진출 팀'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: [{'title': '프로야구 포스트시즌 경기 일정 및 결과 총정리 2024 - 만개의 축제', 'url': 'https://filmk.tistory.com/entry/%ED%94%84%EB%A1%9C%EC%95%BC%EA%B5%AC-%ED%8F%AC%EC%8A%A4%ED%8A%B8%EC%8B%9C%EC%A6%8C-%EA%B2%BD%EA%B8%B0-%EC%9D%BC%EC%A0%95-%EB%B0%8F-%EA%B2%B0%EA%B3%BC-%EC%B4%9D%EC%A0%95%EB%A6%AC2024', 'content': '2024 한국 프로야구 플레이오프에서 승리한 팀은 KIA와 맞붙게 되며, 그 승부는 한국시리즈 진출을 결정짓는 중요한 대결이 될 것입니다. 각 팀이 전력을', 'score': 0.80698997}, {'title': '2024 KBO 한국 프로야구 포스트시즌 일정 순위 예매 (와일드카드 준 ...', 'url': 'https://m.blog.naver.com/qhadldhaus98/223605904423', 'content': '야구 골수팬들은 당연히\\n팀 순위가 머리 속에 있을 수 있지만\\n라이트 팬들은 상위권이랑\\n내가 응원하는 팀만 알지 어느팀이 몇위였더라?\\n잘 모르실 수 있습니다.\\n일단 2024 프로야구 순위를 먼저 적어보겠습니다.\\n\\u200b\\n1.KIA 타이거즈\\n2.삼성 라이온즈\\n3.LG 트윈스\\n4.두산 베어스\\n5.KT 위즈\\n6.SSG 랜더스\\n7.롯데 자이언츠\\n8.한화 이글스\\n9.NC 다이노스\\n10.키움 히어로즈\\n\\u200b\\n올 해 프로야구 포스트시즌에 진출한 팀들은\\nKIA 타이거즈 삼성 라이온즈 LG 트윈스\\n두산 베어스 KT위즈입니다.\\n\\n출처 KBO\\n\\n출처 두산베어스\\n\\n출처 두산베어스\\n\\n출처 KT위즈\\n\\n출처 KT위즈\\n\\n2024 프로야구 일정 와일드카드 결정전 [...] 2024 프로야구 포스트시즌 일정의 그 첫 일정은\\n4위 두산 베어스와 5위 KT 위즈와의 경기였습니다.\\n첫 경기인 10월 2일 4:0 오늘 경기 1:0으로\\n4위 두산 베어스를 꺾고 5위 KT 위즈가\\nKBO 준플레이오프에 진출하게 되었습니다.\\n5위가 4위를 이긴건 KBO 와일드카드 결정전 시작하고\\n처음 있는 일이었습니다. KT위즈 새역사를 쓰다.\\nKT위즈는 LG 트윈스와\\n10월 5일 잠실에서 KBO준플레이오프\\n1차전에서 만나게 됩니다.\\n\\n출처 LG 트윈스\\n\\n출처 LG 트윈스\\n\\u200b\\n\\n\\n출처 KT위즈\\n\\n2024 KBO 준플레이오프 경기 일정 및 프로야구 예매 안내 [...] 2024 KBO 한국 프로야구 포스트시즌 일정 순위 예매 (와일드카드 준플레이오프 플레이오프 한국시리즈)\\n\\u200b\\n2024 KBO리그 한국 프로야구\\n가을야구가 드디어 시작되었습니다.\\n야구 팬들이 기다리던 한국 프로 야구 포스트시즌은\\n10월 2일 와일드카드 결정전을 시작으로\\n본격적인 경쟁이 시작되었습니다.\\n정규 시즌 내내 치열한 승부 끝에 올라온 팀들이\\n한국시리즈 우승을 향해 도전합니다.\\n\\u200b\\n\\u200b\\n변경된 일정\\n\\n\\n\\n플레이오프 일정 변경\\n\\n\\n2024 KBO 포스트시즌 일정\\n\\n와일드카드 결정전: KT, 두산 2-0으로 승리 (KT 준PO 진출)\\n준플레이오프: 10월 5일~10월 11일 (필요 시)\\n플레이오프: 10월 13일~10월 20일 (필요 시)\\n한국시리즈: 10월 21일~10월 29일 (필요 시)\\n경기 시간: 주중 18시 30분, 주말 및 공휴일 14시.\\n\\n출처 KBO\\n\\n2024 KBO리그 한국 프로 야구 순위', 'score': 0.8020137}, {'title': 'KBO 플레이오프/2024년 - 나무위키:대문', 'url': 'https://namu.wiki/w/KBO%20%ED%94%8C%EB%A0%88%EC%9D%B4%EC%98%A4%ED%94%84/2024%EB%85%84', 'content': '... 년 한국시리즈가 마지막이다. 나눔 올스타 팀 중 LG 트윈스가 플레이오프 진출을, KIA 타이거즈가 한국시리즈 직행을 하면서 앞으로의 포스트시즌', 'score': 0.798077}, {'title': '2024년 최강팀 가릴 가을야구, 10월2일 막 오른다 - 한겨레', 'url': 'https://www.hani.co.kr/arti/sports/baseball/1159732.html', 'content': '2024년 9월16일 서울 잠실야구장에서 열린 프로야구 KBO리그 키움 히어로즈와 두산 베어스의 경기에서 관중들이 응원전을 하고 있다. 연합뉴스\\n2024 KBO리그 포스트시즌이 10월2일 와일드카드 1차전을 시작으로 막을 올린다.\\n최대 2경기까지 이어지는 와일드카드 결정전은 10월2일부터 3일까지 정규리그 4위의 홈구장에서 열린다. 현재 최소 5위를 확보한 두산은 4위로 와일드카드 결정전을 홈인 잠실야구장에서 치르길 벼르고 있다. 가을야구 마지막 티켓을 놓고선 케이티(KT) 위즈와 에스에스지(SSG) 랜더스가 막판 경쟁을 벌이고 있다. 수원과 인천의 싸움이다.\\n와일드카드 결정전에서 5위 팀은 두 경기에서 모두 이겨야만 준플레이오프에 진출할 수 있다. 만약 첫번째 경기에서 지거나 무승부를 기록하면 4위가 준플레이오프에 진출한다.\\n광고 [...] 3위로 정규리그를 마감한 엘지(LG) 트윈스는 10월5일 홈구장인 잠실야구장에서 준플레이오프 첫 경기를 치른다. 5전3선승제로 진행되는 준플레이오프는 3위 팀 홈구장에서 1·2·5차전을, 와일드카드 결정전 승리 팀의 홈구장에서 3·4차전을 치른다.\\n준플레이오프 승자는 플레이오프에 진출해 정규리그 2위 삼성 라이온즈와 맞붙는다. 5전3선승제로 진행되고 1·2·5차전은 10월13일 대구 삼성라이온즈파크에서 열린다. 대망의 한국시리즈는 7전4선승제로 진행된다. 기아(KIA) 타이거즈는 플레이오프에서 이긴 팀과 10월21일 광주 기아챔피언스필드에서 1차전을 치른다.\\n광고\\n광고 [...] 시민 10만명, 체감 -10도에도 “내란 안 끝나” 분노의 집회 \\n“작은 윤석열까지 몰아내자” 대학생들 극우 비판 시국선언 [영상] \\n‘헌재 난동’ 모의 정황 온라인 커뮤니티…건물 도면도 올려 \\n\\n# 다시 트럼프 시대구독\\n\\n트럼프, ‘정부 비판’ 퓰리처상 수상 기자에 “즉시 해고돼야” \\n트럼프 “말도 안 되는 종이 빨대…플라스틱으로 돌아간다” \\n트럼프, ‘북한 완전 비핵화’ 원칙 첫 천명…“김정은 다시 만날 것” \\n\\n# 이재명 사법 리스크구독\\n\\n이재명 측근 김용, 항소심서도 징역 5년 법정구속 \\n이재명 ‘위헌법률심판 제청’ 선거법 재판부 “예정대로 2월 말 결심” \\n권성동, ‘이재명 위헌심판 제청 신청’에 “선거로 죄악 덮겠단 뜻” \\n\\n# 기후 위기구독\\n\\n일요일에도 한파 지속…충청·전라·제주엔 눈 또는 비 \\n윤석열 ‘대왕고래’ 8달 만에 실패…산업부 “경제성 없다” \\n탄소 포집·활용 지원하는 법률 시행…기후위기 대응·경제성은 ‘물음표’ \\n\\n# 가자 전쟁구독', 'score': 0.7890553}, {'title': '2024 프로야구 플레이오프: 9개 구단의 치열한 우승 경쟁', 'url': 'https://aldalsuin.tistory.com/entry/2024-%ED%94%84%EB%A1%9C%EC%95%BC%EA%B5%AC-%ED%94%8C%EB%A0%88%EC%9D%B4%EC%98%A4%ED%94%84-9%EA%B0%9C-%EA%B5%AC%EB%8B%A8%EC%9D%98-%EC%B9%98%EC%97%B4%ED%95%9C-%EC%9A%B0%EC%8A%B9-%EA%B2%BD%EC%9F%81', 'content': '2024 프로야구 플레이오프에 진출한 팀들의 면면을 살펴보면, 각 팀마다 독특한 강점과 전략이 돋보입니다. 정규시즌 1위 팀부터 와일드카드 진출팀까지,', 'score': 0.7730283}]\n",
      "[최종 답변]\n",
      "2024년 프로야구 플레이오프에 진출한 팀들은 다음과 같습니다:\n",
      "\n",
      "1. KIA 타이거즈\n",
      "2. 삼성 라이온즈\n",
      "3. LG 트윈스\n",
      "4. 두산 베어스\n",
      "5. KT 위즈\n",
      "\n",
      "이 팀들은 정규 시즌 성적에 따라 포스트시즌에 진출하였으며, 플레이오프와 한국시리즈에서 경쟁하게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import AgentStreamParser\n",
    "\n",
    "# 각 단계별 출력을 위한 파서 생성\n",
    "agent_stream_parser = AgentStreamParser()\n",
    "\n",
    "# 질의에 대한 답변을 스트리밍으로 출력 요청\n",
    "result = agent_executor.stream(\n",
    "    {\"input\": \"2024년 프로야구 플레이오프 진출한 5개 팀을 검색하여 알려주세요.\"}\n",
    ")\n",
    "\n",
    "for step in result:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747b84d",
   "metadata": {},
   "source": [
    "#### **VectorDB에 있는 Retriever 가 필요한 질문**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f06f80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[도구 호출]\n",
      "Tool: pdf_search\n",
      "query: 삼성전자 생성형 AI\n",
      "Log: \n",
      "Invoking: `pdf_search` with `{'query': '삼성전자 생성형 AI'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\n",
      "\n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\n",
      "   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\n",
      "   ▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망··········································· 12\n",
      "   ▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································ 13\n",
      "   ▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화···························································· 14\n",
      " 3. 기술/연구\n",
      "   ▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표······························································ 15\n",
      "   ▹ 구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························ 16\n",
      "   ▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수 ··········································· 17\n",
      "   \n",
      " 4. 인력/교육     \n",
      "   ▹ 영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아······························· 18\n",
      "   \n",
      "   \n",
      " \n",
      "Ⅱ. 주요 행사\n",
      "   ▹CES 2024 ····························································································································· 19\n",
      "[최종 답변]\n",
      "삼성전자가 자체 개발한 생성형 AI 모델인 '삼성 가우스'에 대한 정보는 다음과 같습니다:\n",
      "\n",
      "- **모델 구성**: 삼성 가우스는 언어, 코드, 이미지의 3개 모델로 구성되어 있으며, 온디바이스에서 작동할 수 있도록 설계되었습니다.\n",
      "- **정보 보호**: 온디바이스 작동이 가능하므로 사용자 정보가 외부로 유출될 위험이 없다는 장점이 있습니다.\n",
      "- **최초 공개**: 이 모델은 2023년 11월 8일 열린 '삼성 AI 포럼 2023'에서 처음 공개되었습니다.\n",
      "- **모델의 기능**:\n",
      "  - **언어 모델**: 메일 작성, 문서 요약, 번역 등의 작업을 지원합니다.\n",
      "  - **코드 모델**: AI 코딩 어시스턴트 '코드아이(code.i)'를 통해 대화형 인터페이스로 서비스를 제공하며, 사내 소프트웨어 개발에 최적화되어 있습니다.\n",
      "  - **이미지 모델**: 창의적인 이미지를 생성하고 기존 이미지를 수정할 수 있으며, 저해상도 이미지를 고해상도로 변환하는 기능도 지원합니다.\n",
      "- **제품 탑재 계획**: 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획입니다.\n",
      "\n",
      "이 정보는 삼성전자가 AI 기술을 통해 경쟁력을 강화하고 있음을 보여줍니다.\n"
     ]
    }
   ],
   "source": [
    "# 질의에 대한 답변을 스트리밍으로 출력 요청\n",
    "result = agent_executor.stream(\n",
    "    {\"input\": \"삼성전자가 자체 개발한 생성형 AI 관련된 정보를 문서에서 찾아주세요.\"}\n",
    ")\n",
    "\n",
    "for step in result:\n",
    "    # 중간 단계를 parser 를 사용하여 단계별로 출력\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f86de802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[도구 호출]\n",
      "Tool: tavily_search_results_json\n",
      "query: Attention is All You Need Transformer architecture\n",
      "Log: \n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Attention is All You Need Transformer architecture'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: [{'title': 'Attention Is All You Need - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Attention_Is_All_You_Need', 'content': '\"Attention Is All You Need\"[1] is a 2017 landmark[2][3] research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al.[4] It is considered a foundational[5] paper in modern artificial intelligence, as the transformer approach has become the main architecture of large language models like those based on GPT.[6][7] At the time, [...] The paper is most well known for the introduction of the Transformer architecture, which forms the underlying architecture for most forms of modern Large Language Models (LLMs). A key reason for why the architecture is preferred by most modern LLMs is the parallelizability of the architecture over its predecessors. This ensures that the operations necessary for training can be accelerated on a GPU allowing both faster training times and models of bigger sizes to be trained. [...] Since 2020, Transformers have been applied in modalities beyond text, including the vision transformer,[39] speech recognition,[40] robotics,[41] and multimodal.[42] The vision transformer, in turn, stimulated new developments in convolutional neural networks.[43] Image and video generators like DALL-E (2021), Stable Diffusion 3 (2024),[44] and Sora (2024), are based on the Transformer architecture.\\nTraining[edit]', 'score': 0.89567816}, {'title': 'Attention Is All You Need : A Complete Guide to Transformers', 'url': 'https://medium.com/@alejandro.itoaramendia/attention-is-all-you-need-a-complete-guide-to-transformers-8670a3f09d02', 'content': 'The transformer follows an architecture containing stacked attention layers followed by fully connected layers in both the encoder and decoder. This architecture is illustrated below.\\nIf this seems daunting, do not worry — it will all make sense shortly! [...] The transformer is an architecture that relies on the concept of attention, a technique used to provide weights to different parts of an input sequence so that a better understanding of its underlying context is achieved. This allows transformers to perform machine translation, text generation and many other NLP tasks.\\nIn addition, transformers process inputs in parallel making them more efficient and scalable in comparison to traditional sequential models such as RNN and LSTM. [...] The transformer follows an encoder-decoder structure. At first, word embedding vectors of the input sequence are created. These are then added element-wise to the positional encoding vectors. This resulting matrix is then fed into the encoder and decoder, where it will then under go multi-head self-attention, fully connected feed-forward networks and layer normalisation. Residual connections are additionally implemented in order to help preserve information and make the model more efficient. In', 'score': 0.87139857}, {'title': '[PDF] Attention is All you Need - NIPS papers', 'url': 'https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf', 'content': 'The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.\\n3.1 Encoder and Decoder Stacks Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-2 Figure 1: The Transformer - model architecture. [...] In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs. [...] convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model', 'score': 0.84215075}, {'title': 'Understanding “Attention Is All You Need” | by Santosh Pandey', 'url': 'https://medium.com/@santoshpandey987/understanding-attention-is-all-you-need-750713a1631b', 'content': 'The Transformer architecture consists of two main parts: Encoder: Processes the input sequence. Decoder: Produces the output sequence. Each part', 'score': 0.838376}, {'title': '[1706.03762] Attention Is All You Need - arXiv', 'url': 'https://arxiv.org/abs/1706.03762', 'content': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more', 'score': 0.78194773}]\n",
      "[도구 호출]\n",
      "Tool: pdf_search\n",
      "query: Transformer architecture\n",
      "Log: \n",
      "Invoking: `pdf_search` with `{'query': 'Transformer architecture'}`\n",
      "\n",
      "\n",
      "\n",
      "[관찰 내용]\n",
      "Observation: GPT-4와 거의 동등한 성능을 발휘\n",
      "∙메타의 라마2(Llama-2-70b)는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴 \n",
      "형식의 텍스트 생성에서도 GPT-4에 준하는 성능을 기록했으나, RAG 포함 질문과 답변에서는 허깅 \n",
      "페이스의  제퍼(Zephyr-7b)가 라마2를 능가\n",
      "<갈릴레오의 LLM 환각 지수(RAG 포함 질문과 답변 기준)>\n",
      "☞ 출처: Galileo, LLM Hallucination Index, 2023.11.15.\n",
      "\n",
      "16\n",
      "구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표\n",
      "n 구글 딥마인드 연구진이 성능과 범용성, 자율성을 기준으로 범용 AI(AGI)의 수준을 \n",
      "0~5단계까지 총 6단계로 구분한 프레임워크를 공개\n",
      "n 현재 AGI는 단백질 구조를 예측하는 알파폴드와 같은 특정 용도에서는 5단계 수준을 달성했지만 \n",
      "광범위하게 활용될 수 있는 범용에서는 1단계 수준에 머물러 있음\n",
      "KEY Contents\n",
      "£ 챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준\n",
      "n 구글 딥마인드 연구진은 2023년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와 \n",
      "성능에 따라 분류하는 프레임워크를 제시한 논문을 발표\n",
      "∙프레임워크의 목적은 AGI의 성능, 범용성, 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI \n",
      "달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함\n",
      "n 연구진은 AGI 개념 정의에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출\n",
      "∙(프로세스가 아닌 기능에 중점) AI가 어떻게 작동하는지보다 무엇을 할 수 있는지가 더 중요\n",
      "∙(범용성과 성능을 모두 평가) 진정한 AGI는 인간을 능가하는 폭넓은 범용성과 기술의 깊이를 모두 요구\n",
      "∙(인지와 메타인지 작업에 중점) 물리적 작업의 수행 능력은 AGI의 필수 전제조건이 아니며, 인지 작업과 \n",
      "메타인지 작업(예; 새로운 작업의 학습 능력, 인간에게 도움을 요청할 시점을 아는 능력)이 핵심\n",
      "∙(실제 구현보다 잠재력에 집중) 통제된 상황에서 발휘되는 성능에 따라 AGI를 규정하고 테스트를 진행 \n",
      "∙(생태학적 타당도를 갖춘 벤치마크 사용) AGI에 대한 벤치마크는 사람들이 경제적· 사회적 또는 예술적으로 \n",
      "가치 있게 여기는 실질적인 작업을 대상으로 성능 평가 필요\n",
      "∙(종점이 아닌 AGI를 향한 경로에 중점) 단계별 접근방식을 통해 AGI의 발전 상태를 점진적으로 측정\n",
      "\n",
      "∙(생태학적 타당도를 갖춘 벤치마크 사용) AGI에 대한 벤치마크는 사람들이 경제적· 사회적 또는 예술적으로 \n",
      "가치 있게 여기는 실질적인 작업을 대상으로 성능 평가 필요\n",
      "∙(종점이 아닌 AGI를 향한 경로에 중점) 단계별 접근방식을 통해 AGI의 발전 상태를 점진적으로 측정\n",
      "n 연구진은 상기 원칙에 따라 AI를 성능에 따라 0~5단계와 광범위한 목적에 활용될 수 있는 범용 AI 및 특정 \n",
      "과업에 활용되는 특수 AI로 분류했으며, 특수 AI에서는 5단계까지 달성되었으나, 범용 AI는 현재 1단계 수준\n",
      "성능\n",
      "특수 AI 예시\n",
      "범용 AI 예시\n",
      "0단계: AI 아님\n",
      "계산기 소프트웨어, 컴파일러\n",
      "아마존 메커니컬 터크\n",
      "1단계: 신진(숙련되지 않은 인간)\n",
      "GOFAI(Good Old Fashioned Artificial Intelligence) \n",
      "챗GPT, 바드, 라마2\n",
      "2단계: 유능(숙련된 인간의 50% 이상)\n",
      "스마트 스피커(애플 시리, 아마존 알렉사, 구글 \n",
      "어시스턴트), IBM 왓슨 \n",
      "미달성\n",
      "3단계: 전문가(숙련된 인간의 90% 이상)\n",
      "문법 교정기(그래머리), 생성 이미지 모델(달리2)\n",
      "미달성\n",
      "4단계: 거장(숙련된 인간의 99% 이상) \n",
      "딥블루, 알파고\n",
      "미달성\n",
      "5단계: 초인간(인간을 100% 능가)\n",
      "알파폴드, 알파제로, 스톡피시\n",
      "미달성\n",
      "<구글 딥마인드의 범용 AI 분류 프레임워크> \n",
      "☞ 출처 : Arxiv.org, Levels of AGI: Operationalizing Progress on the Path to AGI, 2023.11.04.\n",
      "[최종 답변]\n",
      "\"Attention is All You Need\" 논문에서 소개된 Transformer 구조는 주로 두 가지 주요 구성 요소로 이루어져 있습니다: **인코더(Encoder)**와 **디코더(Decoder)**입니다. 이 구조는 다음과 같은 특징을 가지고 있습니다.\n",
      "\n",
      "1. **인코더와 디코더 스택**:\n",
      "   - 인코더는 입력 시퀀스를 처리하고, 디코더는 출력 시퀀스를 생성합니다.\n",
      "   - 각 인코더와 디코더는 여러 개의 동일한 레이어로 구성되어 있습니다. 일반적으로 인코더와 디코더 각각 6개의 레이어가 사용됩니다.\n",
      "\n",
      "2. **멀티헤드 셀프 어텐션(Multi-Head Self-Attention)**:\n",
      "   - 인코더의 각 레이어는 멀티헤드 셀프 어텐션 메커니즘을 사용하여 입력 시퀀스의 각 단어가 다른 단어와 어떻게 관련되는지를 학습합니다.\n",
      "   - 이 메커니즘은 입력의 모든 단어 간의 관계를 동시에 고려할 수 있게 해줍니다.\n",
      "\n",
      "3. **피드포워드 네트워크(Feed-Forward Networks)**:\n",
      "   - 각 인코더와 디코더 레이어는 멀티헤드 어텐션 후에 피드포워드 신경망을 포함합니다. 이 네트워크는 각 위치에 대해 독립적으로 작동합니다.\n",
      "\n",
      "4. **포지셔널 인코딩(Positional Encoding)**:\n",
      "   - Transformer는 순차적인 데이터 처리 방식이 아닌 병렬 처리를 사용하기 때문에, 입력 시퀀스의 단어 순서를 인식하기 위해 포지셔널 인코딩을 추가합니다. 이는 각 단어의 위치 정보를 제공합니다.\n",
      "\n",
      "5. **잔차 연결(Residual Connections)**:\n",
      "   - 각 서브 레이어(어텐션과 피드포워드 네트워크) 뒤에는 잔차 연결이 있어, 정보가 손실되지 않도록 합니다. 이는 학습을 더 효율적으로 만들어 줍니다.\n",
      "\n",
      "6. **레이어 정규화(Layer Normalization)**:\n",
      "   - 각 서브 레이어의 출력에 대해 레이어 정규화를 적용하여 학습의 안정성을 높입니다.\n",
      "\n",
      "Transformer 구조는 이러한 특성 덕분에 기존의 순환 신경망(RNN)이나 합성곱 신경망(CNN)보다 더 빠르고 효율적으로 학습할 수 있으며, 특히 대규모 데이터셋에서 뛰어난 성능을 발휘합니다. 이 구조는 현재 많은 자연어 처리(NLP) 작업에서 표준으로 자리잡고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 질의에 대한 답변을 스트리밍으로 출력 요청\n",
    "result = agent_executor.stream(\n",
    "    {\"input\": \"Attenion is all you need 라는 논문에 나온 Transformer 구조에 대해서 알려줘\"}\n",
    ")\n",
    "\n",
    "for step in result:\n",
    "    # 중간 단계를 parser 를 사용하여 단계별로 출력\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
