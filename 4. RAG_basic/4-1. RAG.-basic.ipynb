{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RAG 기본 구조 이해하기**\n",
    "\n",
    "### **1. 사전작업(Pre-processing) - 1~4 단계**\n",
    "\n",
    "<img src='https://ifh.cc/g/VK9RJ9.png' width = \"800\">\n",
    "<img src='https://velog.velcdn.com/images/jjlee6496/post/f4443dd4-cdca-4e4c-83e6-8ec515c21db5/image.png' width = \"800\">\n",
    "\n",
    "\n",
    "사전 작업 단계에서는 데이터 소스를 Vector DB (저장소) 에 문서를 로드-분할-임베딩-저장 하는 4단계를 진행\n",
    "\n",
    "- 1단계 : 도큐먼트 로드 (Document Loader): 외부 데이터 소스에서 필요한 문서를 로드하고 초기 처리. \n",
    "    - 이것은 마치 책을 여러 권 챙겨 도서관에서 공부하는 것과 비슷. 학생이 공부하기 전에 필요한 책들을 책장에서 골라오는 과정.\n",
    "\n",
    "- 2단계 : 텍스트 분할 (Text Splitter): 로드된 문서를 처리 가능한 작은 단위로 분할. 큰 책을 챕터별로 나누는 것과 유사.\n",
    "\n",
    "- 3단계 : 임베딩 (Embedding): 각 문서 또는 문서의 일부를 벡터 형태로 변환하여, 문서의 의미를 수치화. 이는 책의 내용을 요약하여 핵심 키워드로 표현하는 것과 비슷.\n",
    "\n",
    "- 4단계 : 벡터스토어(Vector Store) 저장: 임베딩된 벡터들을 데이터베이스에 저장. 이는 요약된 키워드를 색인화하여 나중에 빠르게 찾을 수 있도록 하는 과정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **2. RAG 수행(RunTime) - 5~8 단계**\n",
    "\n",
    "<img src='https://ifh.cc/g/plorDw.png' width = \"800\">\n",
    "\n",
    "<img src='https://velog.velcdn.com/images/jjlee6496/post/15b30fe5-1015-47b4-b837-d692f9a101fd/image.png' width = \"800\">\n",
    "\n",
    "\n",
    "- 5단계 검색기(Retriever): 쿼리(Query) 를 바탕으로 DB에서 검색하여 결과를 가져오기 위하여 Retriever 정의.\n",
    "    - Retriever는 검색 알고리즘\n",
    "    - Dense: 유사도 기반 검색, Sparse: 키워드 기반 검색\n",
    "- 6단계 프롬프트: RAG 를 수행하기 위한 프롬프트를 생성. 프롬프트의 context 에는 문서에서 검색된 내용이 입력됨. \n",
    "    - 프롬프트 엔지니어링을 통하여 답변의 형식을 지정할 수 있음.\n",
    "- 7단계 LLM: 모델을 정의.(GPT-3.5, GPT-4, Claude, etc..)\n",
    "- 8단계 Chain: 프롬프트 - LLM - 출력 에 이르는 체인을 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pages docs\n"
     ]
    }
   ],
   "source": [
    "loader = PyMuPDFLoader('data/test.pdf')\n",
    "docs = loader.load()\n",
    "print(f'{len(docs)} pages docs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into characters\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 50)\n",
    "split_docs = splitter.split_documents(docs)    # chunk_size : 몇 단어씩 자를 것인지, chunk_overlap : 몇 단어씩 겹칠 것인지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VectorDB 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(documents=split_docs, embedding=embeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retriever 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **프롬프트 생성(Create Prompt)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **언어모델 생성(Chain)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model = 'gemma2-9b-it')\n",
    "\n",
    "chain = (\n",
    "    {'context' : retriver, 'question' : RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **출력**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서에 나와있는 사원 명단은 다음과 같습니다:\n",
      "\n",
      "* 김철수\n",
      "* 이영희\n",
      "* 박민준 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain.stream('사원들의 성명을 알려주세요')\n",
    "\n",
    "for c in response:\n",
    "    print(c, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
