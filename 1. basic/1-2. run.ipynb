{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LangChain LLM í˜¸ì¶œ ë°©ì‹ ì •ë¦¬**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ **ì „ì²´ ì •ë¦¬**\n",
    "| ë©”ì„œë“œ | ë™ê¸°/ë¹„ë™ê¸° | ê¸°ëŠ¥ | ì‚¬ìš© ì˜ˆì œ |\n",
    "|--------|------------|------|----------|\n",
    "| `invoke()` | ë™ê¸° | ë‹¨ì¼ ìš”ì²­ ì²˜ë¦¬ | `chain.invoke({\"input\": \"ì§ˆë¬¸\"})` |\n",
    "| `stream()` | ë™ê¸° | ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ | `for chunk in chain.stream({\"input\": \"ì§ˆë¬¸\"}): print(chunk.content)` |\n",
    "| `batch()` | ë™ê¸° | ì—¬ëŸ¬ ê°œì˜ ìš”ì²­ ì²˜ë¦¬ (ë°°ì¹˜) | `chain.batch([{ \"input\": \"A\" }, { \"input\": \"B\" }])` |\n",
    "| `ainvoke()` | ë¹„ë™ê¸° | ë‹¨ì¼ ìš”ì²­ ì²˜ë¦¬ (async) | `await chain.ainvoke({\"input\": \"ì§ˆë¬¸\"})` |\n",
    "| `astream()` | ë¹„ë™ê¸° | ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (async) | `async for chunk in chain.astream({\"input\": \"ì§ˆë¬¸\"}): print(chunk.content)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¥ **ì–´ë–¤ ê±¸ ì¨ì•¼ í• ê¹Œ?**\n",
    "- **ë‹¨ì¼ ìš”ì²­ ì‹¤í–‰** â†’ `invoke()`\n",
    "- **ì—¬ëŸ¬ ê°œì˜ ìš”ì²­ì„ í•œ ë²ˆì— ì‹¤í–‰ (ë°°ì¹˜)** â†’ `batch()`\n",
    "- **ì‹¤ì‹œê°„ ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)** â†’ `stream()`\n",
    "- **ë¹„ë™ê¸° ë‹¨ì¼ ìš”ì²­ (FastAPI ë“±)** â†’ `ainvoke()`\n",
    "- **ë¹„ë™ê¸° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ** â†’ `astream()`\n",
    "\n",
    "ğŸ“Œ **ë¹„ë™ê¸° í™˜ê²½ì´ ì•„ë‹ˆë¼ë©´ `invoke()`ì™€ `stream()`ì„ ì£¼ë¡œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤!** ğŸš€ğŸ”¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### âœ… 1. `invoke()`\n",
    "#### ê¸°ëŠ¥\n",
    "- ë‹¨ì¼ ì…ë ¥ì„ ë°›ì•„ LLMì„ í˜¸ì¶œí•˜ê³  ì‘ë‹µì„ ë°˜í™˜\n",
    "- ì²´ì¸(`|`)ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ì§ì ‘ ëª¨ë¸ì„ í˜¸ì¶œí•  ë•Œ ì‚¬ìš©\n",
    "- **ë¹„ë™ê¸° ì²˜ë¦¬ X** (ë™ê¸° ë°©ì‹)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model = 'gemma2-9b-it', max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ìì—°ì–´ ì²˜ë¦¬ (Natural Language Processing, NLP) ì— ëŒ€í•´ ì•Œë ¤ë“œë¦´ê²Œìš”!\n",
      "\n",
      "ìì—°ì–´ ì²˜ë¦¬ë€ **ì»´í“¨í„°ê°€ ì¸ê°„ì´ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ **ì…ë‹ˆë‹¤. \n",
      "\n",
      "ì‰½ê²Œ ë§í•´, ì»´í“¨í„°ê°€ ìš°ë¦¬ê°€ ë§í•˜ê±°ë‚˜ ì“°ëŠ” ê¸€ì„ ì½ê³  ì´í•´í•˜ê³ , ê·¸ì— ë§ëŠ” ë‹µë³€ì„ ìƒì„±í•˜ê±°ë‚˜ ë¶„ì„, ìš”ì•½, ë²ˆì—­ ë“± ë‹¤ì–‘í•œ\n"
     ]
    }
   ],
   "source": [
    "### ì˜ˆì œ\n",
    "response = llm.invoke(\"ìì—°ì–´ì²˜ë¦¬ë€?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### âœ… 2. `stream()`\n",
    "#### ê¸°ëŠ¥\n",
    "- LLM ì‘ë‹µì„ **ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹**ìœ¼ë¡œ ë°›ì•„ì˜´\n",
    "- ë¶€ë¶„ì ìœ¼ë¡œ ìƒì„±ëœ ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥\n",
    "- **ì˜ˆ: ì±„íŒ… ì•±, ì‹¤ì‹œê°„ ì‘ë‹µì´ í•„ìš”í•œ ê²½ìš°**\n",
    "\n",
    "â¡ï¸ **ëª¨ë¸ì˜ ì‘ë‹µì„ í•œ ë²ˆì— ë°›ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í† í° ë‹¨ìœ„ë¡œ ë¶€ë¶„ ì¶œë ¥ë¨**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ìì—°ì–´ ì²˜ë¦¬ (Natural Language Processing, NLP)ë€?\n",
      "\n",
      "ìì—°ì–´ ì²˜ë¦¬ (NLP)ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì´ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•˜ë„ë¡ í•˜ëŠ” ì»´í“¨í„° ê³¼í•™ ë¶„ì•¼ì…ë‹ˆë‹¤. \n",
      "\n",
      "ì‰½ê²Œ ë§í•´, ì»´í“¨í„°ê°€ ì‚¬ëŒì²˜ëŸ¼ ë§ì„ ì´í•´í•˜ê³ , ì“¸ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. \n",
      "\n",
      "**NLPëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.**\n",
      "\n",
      "* **"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"ìì—°ì–´ì²˜ë¦¬ë€?\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### âœ… 3. `batch()`\n",
    "#### ê¸°ëŠ¥\n",
    "- **ì—¬ëŸ¬ ê°œì˜ ì…ë ¥ì„ í•œ ë²ˆì— ì²˜ë¦¬** (ë°°ì¹˜ ì²˜ë¦¬)\n",
    "- ì…ë ¥ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ ì¼ê´„ ì‹¤í–‰\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ëŠ” AI, ìì—°ì–´ì²˜ë¦¬ë€?\n",
      "\n",
      "ë„¤, ë§ì•„ìš”!  ğŸ˜Š \n",
      "\n",
      "ì‚¬ìš©ìê°€ ë§í•˜ëŠ” ëŒ€ë¡œ ì´í•´í•˜ê³ , ì‚¬ëŒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•˜ëŠ” AI ê¸°ìˆ ì´ ë°”ë¡œ **ìì—°ì–´ì²˜ë¦¬(Natural Language Processing, NLP)**ì…ë‹ˆë‹¤. \n",
      "\n",
      "ì‰½ê²Œ ë§í•´, ğŸ¤– **ì»´í“¨í„°ê°€ ì‚¬ëŒì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ğŸ¤– \n",
      "\n",
      "ì €ëŠ” ì¹œì ˆí•˜ê²Œ ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦¬ëŠ” AIì…ë‹ˆë‹¤.\n",
      "\n",
      "**ë¨¸ì‹ ëŸ¬ë‹**ì´ë€ ì»´í“¨í„°ê°€ ì‚¬ëŒì²˜ëŸ¼ í•™ìŠµí•˜ê³  ë°ì´í„°ë¥¼ ì´í•´í•˜ì—¬ ì˜ˆì¸¡í•˜ê±°ë‚˜ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ëŠ¥ë ¥ì„ ê°€ì§„ ì»´í“¨í„° ê³¼í•™ ë¶„ì•¼ì…ë‹ˆë‹¤.  \n",
      "\n",
      "ì‰½ê²Œ ë§í•´ì„œ, \n",
      "\n",
      "* ì‚¬ëŒì´ ìˆ˜ë§ì€ ì‚¬ì§„ì„ ë³´ê³  \"ê³ ì–‘ì´\"ì™€ \"ê°œ\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ëŠ” AI\"),\n",
    "    ('user', \"{input}\"),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | llm\n",
    "\n",
    "\n",
    "responses = chain.batch([\n",
    "    {\"input\": \"ìì—°ì–´ì²˜ë¦¬ë€?\"},\n",
    "    {\"input\": \"ë¨¸ì‹ ëŸ¬ë‹ì´ë€?\"}\n",
    "])\n",
    "\n",
    "for res in responses:\n",
    "    print(res.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### âœ… 4. `ainvoke()`\n",
    "#### ê¸°ëŠ¥\n",
    "- `invoke()`ì˜ **ë¹„ë™ê¸°(async) ë²„ì „**\n",
    "- âœ… **ë¹„ë™ê¸° í™˜ê²½ (FastAPI, AsyncIO ë“±)ì—ì„œ ì‚¬ìš©**\n",
    "- âœ… **ì—¬ëŸ¬ ê°œì˜ LLM í˜¸ì¶œì„ ë³‘ë ¬ ì²˜ë¦¬í•  ë•Œ**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”! \n",
      "\n",
      "**ìì—°ì–´ ì²˜ë¦¬(Natural Language Processing, NLP)**ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì²˜ëŸ¼ ìì—°ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. \n",
      "\n",
      "ì‰½ê²Œ ë§í•´, \n",
      "\n",
      "**ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ” í•œêµ­ì–´ë‚˜ ì˜ì–´ ë“±ì˜ ì–¸ì–´ë¥¼ ì»´í“¨í„°ê°€ ì½ê³  ì´í•´í•˜ê³ , ì»´í“¨í„°ê°€ ë§Œë“¤ì–´ë‚´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì‚¬ëŒì´ ì½\n"
     ]
    }
   ],
   "source": [
    "### ğŸ”¹ ì˜ˆì œ\n",
    "import asyncio\n",
    "\n",
    "response = await chain.ainvoke({\"input\": \"ìì—°ì–´ì²˜ë¦¬ë€?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… 5. `astream()`\n",
    "#### ê¸°ëŠ¥\n",
    "- `stream()`ì˜ **ë¹„ë™ê¸°(async) ë²„ì „**\n",
    "- `await`ê³¼ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "#### ğŸ“Œ ì–¸ì œ ì‚¬ìš©í•´ì•¼ í• ê¹Œ?\n",
    "âœ… **ë¹„ë™ê¸° í™˜ê²½ì—ì„œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì´ í•„ìš”í•  ë•Œ**\n",
    "âœ… **ì›¹ì†Œì¼“ ê¸°ë°˜ ì‹¤ì‹œê°„ ì• í”Œë¦¬ì¼€ì´ì…˜ (ì˜ˆ: FastAPI WebSocket)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”! ğŸ˜Š\n",
      "\n",
      "**AI ìì—°ì–´ ì²˜ë¦¬(AI Natural Language Processing, NLP)**ëŠ” ì¸ê³µì§€ëŠ¥(AI) ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤. ì‰½ê²Œ ë§í•´ì„œ, ì»´í“¨í„°ê°€ ìš°ë¦¬ê°€ ë§í•˜ëŠ” ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ëŒ€ë‹µí•˜ë„ë¡ ë§Œë“œëŠ” ê¸°ìˆ ì´ì£ !\n",
      "\n",
      "**AI NLPëŠ” ë‹¤ìŒ"
     ]
    }
   ],
   "source": [
    "async for chunk in chain.astream({\"input\": \"ìì—°ì–´ì²˜ë¦¬ë€?\"}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
