{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **네이버 뉴스 기반 QA(Question-Answering) 챗봇**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "import bs4 # 파싱용\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "국민연금 모수개혁안 논쟁 가열… 野원외 \"성과 인정해야\"\n",
      "\n",
      "\n",
      "여권 이어 민주 인사들도 반박김성주 \"'세대간 전쟁' 아니다\"박용진 \"개혁동력 확장해야\"최근 여야 합의로 국회를 통과한 국민연금 모수개혁안을 두고 정치권에서 논쟁이 이어지고 있다. 특히 한동훈 전 국민의힘 대표, 유승민 전 국민의힘 의원 등 여당 '대권 잠룡'들이 적극적으로 비판의 목소리를 내고 있는 가운데 더불어민주당 원외 인사들이 반박에 나서며 논쟁이 불붙는 양상이다.김성주 더불어민주당 전 의원은 24일 자신의 페이스북에 글을 올려 \"세대 간 연대로 성립하는 연금제도\n"
     ]
    }
   ],
   "source": [
    "# 웹 문서 로드 \n",
    "loader = WebBaseLoader(\n",
    "    \n",
    "    web_paths = ('https://n.news.naver.com/mnews/article/029/0002943263',\n",
    "                 'https://n.news.naver.com/mnews/article/469/0000855476'),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            'div',\n",
    "            attrs = {'class' : ['media_end_head_title', 'newsct_article _article_body']}\n",
    "                     \n",
    "            )\n",
    "    ),\n",
    "    header_template={\n",
    "        \"User_Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\",\n",
    "    },\n",
    ")\n",
    "  \n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embedding Model\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "# Vector Store\n",
    "vector_store = Chroma.from_documents(documents=split_docs, embedding=embeddings)\n",
    "\n",
    "# Retriever \n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'teddynote', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': 'f42521f58f89165b1784695ac09ff4fb7b750dd7227b0aaf952521e91f629e88'} template=\"You are an AI assistant specializing in Question-Answering (QA) tasks within a Retrieval-Augmented Generation (RAG) system. \\nYour primary mission is to answer questions based on provided context or chat history.\\nEnsure your response is concise and directly addresses the question without any additional narration.\\n\\n###\\n\\nYour final answer should be written concisely (but include important numerical values, technical terms, jargon, and names), followed by the source of the information.\\n\\n# Steps\\n\\n1. Carefully read and understand the context provided.\\n2. Identify the key information related to the question within the context.\\n3. Formulate a concise answer based on the relevant information.\\n4. Ensure your final answer directly addresses the question.\\n5. List the source of the answer in bullet points, which must be a file name (with a page number) or URL from the context. Omit if the source cannot be found.\\n\\n# Output Format:\\n[Your final answer here, with numerical values, technical terms, jargon, and names in their original language]\\n\\n**Source**(Optional)\\n- (Source of the answer, must be a file name(with a page number) or URL from the context. Omit if you can't find the source of the answer.)\\n- (list more if there are multiple sources)\\n- ...\\n\\n###\\n\\nRemember:\\n- It's crucial to base your answer solely on the **PROVIDED CONTEXT**. \\n- DO NOT use any external knowledge or information not present in the given materials.\\n- If you can't find the source of the answer, you should answer that you don't know.\\n\\n###\\n\\n# Here is the user's QUESTION that you should answer:\\n{question}\\n\\n# Here is the CONTEXT that you should use to answer the question:\\n{context}\\n\\n# Your final ANSWER to the user's QUESTION:\"\n"
     ]
    }
   ],
   "source": [
    "# Hub에 있는 Pormpt Load\n",
    "prompt = hub.pull('teddynote/rag-prompt')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the answers to the user's questions:\n",
      "\n",
      "1. 산불은 몇건이 발생했나요?\n",
      "5건\n",
      "\n",
      "**Source**\n",
      "- https://n.news.naver.com/mnews/article/469/0000855476\n",
      "\n",
      "2. 산불로 인한 피해에는 어떤것들이 있나요\n",
      "문화유산 5건 (울주 목도 상록수림, 운화리성지, 의성 사촌리 가로숲, 의성 고운사 석조여래좌상, 목조아미타여래좌상)\n",
      "\n",
      "**Source**\n",
      "- https://n.news.naver.com/mnews/article/469/0000855476\n",
      "- https://n.news.naver.com/mnews/article/469/0000855476\n",
      "\n",
      "3. 어느 지역에 산불이 발생했나요\n",
      "경북 의성군, 울산 울주군\n",
      "\n",
      "**Source**\n",
      "- https://n.news.naver.com/mnews/article/469/0000855476\n",
      "- https://n.news.naver.com/mnews/article/469/0000855476"
     ]
    }
   ],
   "source": [
    "# LLM model \n",
    "llm = ChatGroq(model_name = 'llama3-70b-8192')\n",
    "\n",
    "\n",
    "# Chain 생성\n",
    "chain = (\n",
    "    {'context' : retriever, 'question' : RunnablePassthrough()}\n",
    "     | prompt\n",
    "     | llm\n",
    "     | StrOutputParser()\n",
    ")\n",
    "\n",
    "user = '''\n",
    "1. 산불은 몇건이 발생했나요? \n",
    "2. 산불로 인한 피해에는 어떤것들이 있나요\n",
    "3. 어느 지역에 산불이 발생했나요\n",
    "'''\n",
    "\n",
    "response = chain.stream(user)\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk, end = '', flush = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
