{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parent Document Retriever**\n",
    "\n",
    "문서를 검색할 때 **잘게 나누면 의미는 정확히 파악되지만, 맥락이 부족해지고**,  \n",
    "**크게 나누면 맥락은 좋지만 의미가 흐려질 수 있음.**  \n",
    "이 두 가지를 **균형 있게 해결**해주는 게  `ParentDocumentRetriever`\n",
    "\n",
    "- Chunk 하기전 원본 문서\n",
    "\n",
    "- Chunk된 문서와 함께 원본 문서가 필요 할 때 사용 할 수 있음\n",
    "\n",
    "---\n",
    "\n",
    "- 문서를 **작게 나눠서(청크)** 검색에 쓰고,  \n",
    "- 검색된 청크가 속한 **큰 문서(부모 문서)**를 찾아  \n",
    "- 더 풍부한 맥락과 내용을 제공\n",
    "\n",
    "---\n",
    "\n",
    "- **작은 단위로 정확하게 검색**  \n",
    "- **큰 단위로 맥락까지 보장**  \n",
    "- 문서 구조를 잘 활용해서 **검색 효율이 높아짐**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서로드\n",
    "loader = TextLoader('data/appendix-keywords.txt')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 \n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "# 전체 문서 검색\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 200)\n",
    "\n",
    "# vector store\n",
    "vectorstore = Chroma(collection_name='full_documents', embedding_function=embeddings)   # 저장소 이름 : full_documents\n",
    "\n",
    "# InMemoryStore\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Retriever\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,          # Chunking한 문서를 저장하는 저장소\n",
    "    docstore=store,                   # 원본 문서를 저장하는 저장소\n",
    "    child_splitter=child_splitter,\n",
    ")\n",
    "\n",
    "# Retriever에 문서 추가\n",
    "retriever.add_documents(docs, ids = None)    # 원래 벡터스토어 에서 문서를 저장함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chunk에 대한 검색**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색(vectorstore에 유사도 검색을 하면 청크를 검색하게됨)\n",
    "sub_docs = vectorstore.similarity_search(\"Word2Vec\")\n",
    "\n",
    "# sub_docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\n",
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parent(원본 문서)에 대한 검색**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 길이: 5733\n",
      "\n",
      "=====================\n",
      "\n",
      " 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\n",
      "연관키워드: 혁신, 기술, 비즈니스 모델\n",
      "\n",
      "Crawling\n",
      "\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n",
      "\n",
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n",
      "\n",
      "정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을\n"
     ]
    }
   ],
   "source": [
    "# 문서를 검색\n",
    "retrieved_docs = retriever.invoke(\"Word2Vec\")\n",
    "\n",
    "# 검색된 문서의 문서의 페이지 내용의 길이를 출력합니다.\n",
    "print(\n",
    "    f\"문서의 길이: {len(retrieved_docs[0].page_content)}\",\n",
    "    end=\"\\n\\n=====================\\n\\n\",\n",
    ")\n",
    "\n",
    "# 문서의 일부를 출력합니다.\n",
    "print(retrieved_docs[0].page_content[2000:2500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **더 큰 Chunk 의 크기를 조절**\n",
    "\n",
    "전체 문서가 너무 크면 있는 그대로 검색하기에는 부적합\n",
    "\n",
    "이런 경우, 실제로 우리가 하고 싶은 것은 먼저 원시 문서를 더 큰 청크로 분할한 다음, 더 작은 청크로 분할\n",
    "\n",
    "그런 다음 작은 청크들을 인덱싱하지만, 검색 시에는 더 큰 청크를 검색\n",
    "\n",
    "- `RecursiveCharacterTextSplitter`를 사용하여 부모 문서와 자식 문서를 생성\n",
    "  - 부모 문서는 `chunk_size`가 1000으로 설정되어 있음\n",
    "  - 자식 문서는 `chunk_size`가 200으로 설정되어 있으며, 부모 문서보다 작은 크기로 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent Docs Textsplitter\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000)\n",
    "\n",
    "# Child Docs Textsplitter\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 200)\n",
    "\n",
    "# Child Chunk Indexing\n",
    "vectorstore = Chroma(collection_name='split_parents', embedding_function=embeddings)\n",
    "\n",
    "# InMemoryStore(부모문서 저장)\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Retriever\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    parent_splitter=parent_splitter,\n",
    "    child_splitter=child_splitter,\n",
    ")\n",
    "\n",
    "# 문서 추가\n",
    "retriever.add_documents(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색\n",
    "sub_docs = vectorstore.similarity_search(\"Word2Vec\")\n",
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\n",
      "예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\n",
      "연관키워드: 딥러닝, 자연어 처리, Attention\n",
      "\n",
      "HuggingFace\n",
      "\n",
      "정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
      "예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
      "연관키워드: 자연어 처리, 딥러닝, 라이브러리\n",
      "\n",
      "Digital Transformation\n",
      "\n",
      "정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\n",
      "예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\n",
      "연관키워드: 혁신, 기술, 비즈니스 모델\n",
      "\n",
      "Crawling\n",
      "\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n",
      "\n",
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n"
     ]
    }
   ],
   "source": [
    "# 문서 검색\n",
    "retrieved_docs = retriever.invoke(\"Word2Vec\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
