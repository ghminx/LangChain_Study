{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **configurable**\n",
    "\n",
    "ë‹¤ì–‘í•œ ì˜µì…˜(Model, Prompt)ì„ ë™ì ìœ¼ë¡œ ì„¤ì • í•  ìˆ˜ ìˆëŠ” ë°©ë²• \n",
    "\n",
    "- `configurable_fields` \n",
    "    - ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ì˜ íŠ¹ì • í•„ë“œ êµ¬ì„±\n",
    "\n",
    "- `configurable_alternatives`\n",
    "    - ëŸ°íƒ€ì„ ì¤‘ì— ì„¤ì •í•  ìˆ˜ ìˆëŠ” íŠ¹ì • ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ì•  ëŒ€í•œ ëŒ€ì•ˆ ë‚˜ì—´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **configurable_fields**\n",
    "\n",
    "ì‹œìŠ¤í…œì˜ ì„¤ì • ê°’ì„ ì •ì˜í•˜ëŠ” í•„ë“œ\n",
    "\n",
    "- ì‹œìŠ¤í…œì˜ ë™ì‘ ì œì–´, ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ì‹œìŠ¤í…œ êµ¬ì„±\n",
    "- ì„¤ì • íŒŒì¼, í™˜ê²½ ë³€ìˆ˜, ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì œê³µ\n",
    "- DBì—°ê²° ì •ë³´, ë¡œê¹… ì„¤ì •, ë³´ì•ˆ ì˜µì…˜, íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ì•¼.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 17,\n",
       "   'prompt_tokens': 22,\n",
       "   'total_tokens': 39,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-3.5-turbo-0125',\n",
       "  'system_fingerprint': None,\n",
       "  'id': 'chatcmpl-BGQR68TLLw7wfI4G16oD5jfM8BfNJ',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-1ad8fd22-7482-4028-99da-c4b9d2297a00-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 22,\n",
       "  'output_tokens': 17,\n",
       "  'total_tokens': 39,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê¸°ë³¸ ì‚¬ìš© í–ˆì„ë•Œì˜ ì •ë³´ \n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "model.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\").__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Name ë™ì  ì •ì˜\n",
    "model = ChatOpenAI().configurable_fields(\n",
    "    model_name = ConfigurableField(\n",
    "    id = 'gpt_version',\n",
    "    name = 'Version of GPT',\n",
    "    description = 'Get the version of GPT ex) gpt-4o, gpt-3.5-turbo, etc'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-2024-08-06'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\",\n",
    "    config={\"configurable\": {\"gpt_version\": \"gpt-4o\"}},\n",
    ").response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini-2024-07-18'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\",\n",
    "    config={\"configurable\": {\"gpt_version\": \"gpt-4o-mini\"}},\n",
    ").response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini-2024-07-18'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ì—ì„œ ì •ì˜ \n",
    "model.with_config(configurable={\"gpt_version\": \"gpt-4o-mini\"}).invoke(\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\"\n",
    ").response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chain ì„¤ì •**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜')\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini-2024-07-18'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invokeë¥¼ í˜¸ì¶œ í•˜ë©´ì„œ configurableì„ ì„¤ì •í•˜ì—¬ ëª¨ë¸ ë³€ê²½\n",
    "chain.invoke('ëŒ€í•œë¯¼êµ­ìˆ˜ë„', config={\"configurable\": {\"gpt_version\": \"gpt-4o-mini\"}}).response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini-2024-07-18'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì²´ì¸ì—ì„œ ëª¨ë¸ì„ ì •ì˜í•˜ê³  invokeë¡œ llm í˜¸ì¶œ\n",
    "chain.with_config(configurable={\"gpt_version\": \"gpt-4o-mini\"}).invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„\").response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configurable Alternatives: Runnable ê°ì²´ ìì²´ì˜ ëŒ€ì•ˆ ì„¤ì •**\n",
    "\n",
    "- ì„œë¡œë‹¤ë¥¸ ëª¨ë¸ API ê³¼ Promptë¥¼ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import  ChatGroq\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0, model=\"gpt-4o\"\n",
    ").configurable_alternatives(\n",
    "    \n",
    "    # id ì„¤ì •    \n",
    "    ConfigurableField(id=\"llm\"),\n",
    "\n",
    "    # default ì„¤ì •\n",
    "    default_key=\"anthropic\",\n",
    "    \n",
    "    # ëŒ€ì²´ ëª¨ë¸ ì„¤ì •(gpt-4o-mini, gemma2-9b-it)\n",
    "    mini = ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    \n",
    "    gemma = ChatGroq(model =\"gemma2-9b-it\")\n",
    "    \n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"{topic} ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-2024-08-06'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰\n",
    "chain.invoke('ë‰´ì§„ìŠ¤').response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma2-9b-it'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì²´ì¸ì—ì„œ ëª¨ë¸ì„ ì •ì˜í•˜ê³  invokeë¡œ llm í˜¸ì¶œ\n",
    "chain.with_config(configurable={'llm' : 'gemma'}).invoke('ë‰´ì§„ìŠ¤').response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini-2024-07-18'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.invoke('ë‰´ì§„ìŠ¤', configurable={'llm' : 'mini'}).response_metadata['model_name'] => ì´ê±° ì•ˆë¨ => with_configë¡œ ì„¤ì •í•´ì•¼í•¨\n",
    "chain.with_config(configurable={'llm' : 'mini'}).invoke('ë‰´ì§„ìŠ¤').response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prompt ëŒ€ì•ˆ ì„¤ì •**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-4o')\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{country} ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\").configurable_alternatives(\n",
    "    \n",
    "    # id ì„¤ì •\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "\n",
    "    # default ì„¤ì •\n",
    "    default_key=\"capital\",\n",
    "\n",
    "    # ì—¬ëŸ¬ê°€ì§€ í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "    area=PromptTemplate.from_template(\"{country} ì˜ ë©´ì ì€ ì–¼ë§ˆì•¼?\"),\n",
    "    population=PromptTemplate.from_template(\"{country} ì˜ ì¸êµ¬ëŠ” ì–¼ë§ˆì•¼?\"),\n",
    "    eng=PromptTemplate.from_template(\"{input} ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ ê²°ê³¼ë§Œ ì œê³µí•´ì£¼ì„¸ìš”\"),\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default ì„¤ì •\n",
    "chain.invoke('ëŒ€í•œë¯¼êµ­').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ì˜ ë©´ì ì€ ì•½ 100,210 í‰ë°©í‚¬ë¡œë¯¸í„°ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(configurable={'prompt' : 'area'}).invoke('ëŒ€í•œë¯¼êµ­').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€í•œë¯¼êµ­ì˜ ì¸êµ¬ëŠ” ì•½ 5,100ë§Œ ëª… ì •ë„ì…ë‹ˆë‹¤. ì •í™•í•œ ì¸êµ¬ ìˆ˜ì¹˜ëŠ” ì‹œê°„ì— ë”°ë¼ ë³€ë™ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœì‹  í†µê³„ë¥¼ ì°¸ê³ í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(configurable={'prompt' : 'population'}).invoke('ëŒ€í•œë¯¼êµ­').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, nice to meet you. I am currently studying LangChain.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(configurable={'prompt' : 'eng'}).invoke('ì•ˆë…•í•˜ì„¸ìš” ë°˜ê°€ì›Œìš” ë‚˜ëŠ” ì§€ê¸ˆ LangChain ê³µë¶€ì¤‘ì…ë‹ˆë‹¤').content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model & Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0, model=\"gpt-4o\"\n",
    ").configurable_alternatives(\n",
    "    \n",
    "    # id ì„¤ì •    \n",
    "    ConfigurableField(id=\"llm\"),\n",
    "\n",
    "    # default ì„¤ì •\n",
    "    default_key=\"anthropic\",\n",
    "    \n",
    "    # ëŒ€ì²´ ëª¨ë¸ ì„¤ì •(gpt-4o-mini, gemma2-9b-it)\n",
    "    mini = ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    \n",
    "    gemma = ChatGroq(model =\"gemma2-9b-it\")\n",
    "    \n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{country} ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\").configurable_alternatives(\n",
    "    \n",
    "    # id ì„¤ì •\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "\n",
    "    # default ì„¤ì •\n",
    "    default_key=\"capital\",\n",
    "\n",
    "    # ì—¬ëŸ¬ê°€ì§€ í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "    area=PromptTemplate.from_template(\"{country} ì˜ ë©´ì ì€ ì–¼ë§ˆì•¼?\"),\n",
    "    population=PromptTemplate.from_template(\"{country} ì˜ ì¸êµ¬ëŠ” ì–¼ë§ˆì•¼?\"),\n",
    "    eng=PromptTemplate.from_template(\"{input} ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ ê²°ê³¼ë§Œ ì œê³µí•´ì£¼ì„¸ìš”\"),\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.', 'gpt-4o-2024-08-06')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default ì„¤ì •\n",
    "response = chain.invoke('ëŒ€í•œë¯¼êµ­')\n",
    "response.content, response.response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ëŒ€í•œë¯¼êµ­ì˜ ë©´ì ì€ ì•½ 100,210 í‰ë°©í‚¬ë¡œë¯¸í„°ì…ë‹ˆë‹¤. ì´ëŠ” í•œë°˜ë„ì˜ ë‚¨ìª½ ë¶€ë¶„ì— í•´ë‹¹í•˜ë©°, êµ­í† ì˜ ëŒ€ë¶€ë¶„ì´ ì‚°ì§€ì™€ í‰ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.',\n",
       " 'gpt-4o-mini-2024-07-18')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM, Prompt ë™ì‹œ ì„¤ì •\n",
    "response = chain.with_config(configurable = {'prompt' : 'area', 'llm' : 'mini'}).invoke('ëŒ€í•œë¯¼êµ­')\n",
    "response.content, response.response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤. ğŸ˜Š  \\n', 'gemma2-9b-it')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLMë§Œ ì„¤ì •\n",
    "response = chain.with_config(configurable = {'llm' : 'gemma'}).invoke('ëŒ€í•œë¯¼êµ­')\n",
    "response.content, response.response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€í•œë¯¼êµ­ì˜ ì¸êµ¬ëŠ” ì•½ 5,100ë§Œ ëª… ì •ë„ë¡œ ì¶”ì‚°ë©ë‹ˆë‹¤. ì •í™•í•œ ìˆ˜ì¹˜ëŠ” í†µê³„ì²­ì´ë‚˜ ê´€ë ¨ ê¸°ê´€ì˜ ìµœì‹  ìë£Œë¥¼ ì°¸ì¡°í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.',\n",
       " 'gpt-4o-2024-08-06')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Promptë§Œ ì„¤ì •\n",
    "response = chain.with_config(configurable = {'prompt' : 'population'}).invoke('ëŒ€í•œë¯¼êµ­')\n",
    "response.content, response.response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ì„¤ì • ì €ì¥**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.', 'gpt-4o-mini-2024-07-18')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4o_mini = chain.with_config(configurable = {'llm' : 'mini'})\n",
    "response = gpt4o_mini.invoke('ëŒ€í•œë¯¼êµ­')\n",
    "response.content, response.response_metadata['model_name']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
